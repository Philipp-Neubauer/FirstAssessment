\documentclass{article}

\begin{document}

\title{Analysis notes}
\maketitle

V0.0.2 PN

\section{Data manupulation}

<< Data input,results='hide',warning=FALSE>>=

# set dropbox folder for data

DB <- '~/Dropbox'

require(dplyr)
require(ggplot2)

years.table <- tbl_df(read.csv(file.path(DB,'First year of assessment/v7 Final dataset.csv'),
                              na.strings=c('','NA','#N/A'),
                              stringsAsFactors = F)
)

# crossref tables for non-assessed stocks
crossref <- tbl_df(read.csv(file.path(DB,
                                      'First year of assessment/crosref.csv'), 
                            na.strings=c('','NA','#N/A'), 
                            stringsAsFactors = F,dec = ",",header=T))

spec.ref <- read.csv(file.path(DB,
                               'First year of assessment/SpeciesCrossReference.csv'),
                     header=T,
                     stringsAsFactors = F)

reg.ref <- read.csv(file.path(DB,'First year of assessment/region_ref.csv'),header=F,stringsAsFactors = F)
@ 

For the landings data, I excluded a fair few species since they are irrelevant, and groupings since their definitons seem to be inconsistent, and landings therefore fluctuate suspiciously.

<<deal with landings>>=

land.price <- (read.csv(file.path(DB,'First year of assessment/landings-price.csv'), na.strings=c('','NA','#N/A'), stringsAsFactors = F,dec = ",")) %>%
  filter(!grepl('Turtle',Species,ignore.case = T),
         !grepl('Alligator',Species,ignore.case = T),
         !grepl('Coral',Species,ignore.case = T),
         !grepl('Sponge',Species,ignore.case = T),
         !grepl('UNC',Species,ignore.case = T),
         !grepl('WHALES',Species,ignore.case = T),
         !grepl('FROGS',Species,ignore.case = T),
         !grepl('finfishes',Species,ignore.case = T),
         !grepl('groundfishes',Species,ignore.case = T),
         State != "At-Sea Process, Pac.",
         State != 'Hawaii') 

land.price$Price <- as.numeric(gsub(',','',land.price[['Price']]))

land.price$Metric.Tons <- as.numeric(gsub(',','',land.price[['Metric.Tons']]))
@

Time series that start out as groups that were disaggregated (but without assessment), were re-aggregated at group level.

<<fix grouped landings data>>=

#fixes to grouped->disaggregated time series
land.price$Species[grepl('ABALONE',land.price$Species,ignore.case = T)] <- 'ABALONE'

land.price$Species[grepl('AMBERJACK',land.price$Species,ignore.case = T)] <- 'AMBERJACK'

land.price$Species[grepl('BARRAC',land.price$Species,ignore.case = T)] <- 'BARRACUDA'

# dissagregated from 2005
land.price$Species[grepl('SCUP',land.price$Species,ignore.case = T)] <- 'SCUPS OR PORGIES'

#remove shellfish and other generics
land.price <- land.price %>% filter(Species != 'SHELLFISH',
                                    Species != 'TUNAS',
                                    Species != 'SHARKS',
                                    Species != 'BILLFISHES')
@

Regions were matched based on states, where only large subdivision were kept (I.e., SE-sAtl and GoM does not figure)

<<>>=
matches <- match(land.price[,'State'],reg.ref[1,])
matches[is.na(matches)] <- 25
land.price$region <- as.vector(t(reg.ref[2,matches]))
land.price <- land.price %>% filter(region!='INLAND')
land.price$region <- factor(land.price$region)


land.price$Species[grepl('SHRIMP, MA',land.price$Species,ignore.case = T) & (land.price$Year <= 1961 | (land.price$Year >= 1972 & land.price$Year <= 1977)) & land.price$region == 'USEC-SE'] <- 'SHRIMP, WHITE'

@

I reduced the table down to only stocks that had at least 10t of catch at some point over the regional time-series.

<<Some subsetting,cache=TRUE>>=

# only keep stocks where 10t have been caught in a region at some point
suml <- tbl_df(land.price) %>% 
  group_by(region,Species,Year) %>%
  summarise(sums = sum(Metric.Tons,na.rm=T)) %>%
  mutate(flag = any(sums>10)) %>%
  filter(flag == T) %>%
  summarise(catch = sum(sums,na.rm=T)) %>%
  mutate(reg_spec = paste(region,Species))
  
lp <- apply(land.price[,c('Species','region')],1,function(x) {
  tf <- any(grepl(x[1],suml$reg_spec) & grepl(x[2],suml$reg_spec))
  return(tf)
  }) 

land.price <- land.price[lp,]

prop.cols <- grepl('prop',colnames(land.price))
stock.cols <- grepl('stock',colnames(land.price))
land.price[,prop.cols] <- apply(land.price[,prop.cols],2,as.numeric)

@

Stocks were defined as region-species/group, with landings and price totalled over the region.

<<results='hide',cache=TRUE>>=

require(data.table)

l = 84145
stock.landings <- data.table(year = rep(1,l),
                             stock = rep('a',l),
                             species = rep('a',l),
                             state = rep('a',l),
                             region = rep('a',l),
                             landings = rep(1,l),
                             price = rep(1,l))

# clunky, but easy:
a=1
for (i in 1:nrow(land.price)){
  #cat(i,'\n')
  
  stocks <- land.price[i,stock.cols]
  props <- land.price[i,prop.cols]
  region <- land.price[i,'region']
  state = land.price[i,'State']
  species <- spec.ref$SCIENTIFIC_NAME[match(land.price$Species[i],spec.ref$AFS_NAME)]
  
  if(any(!(is.na(stocks)))){
    land <- unlist(sapply(which(!is.na(stocks)),function(s) props[s]*land.price[i,'Metric.Tons']))
    
  } else { # apply a region-stock combo
    #region <- reg.ref[2,reg.ref[1,]==land.price[i,'State']]
    #region <- ifelse(!is.null(dim(region)), 'Inland', region)
    stocks  <-paste(region,land.price$Species[i])
    land <- land.price[i,'Metric.Tons']
  }
  
  
  l = length(which(!is.na(stocks)))
  
  set(stock.landings,a:(a+l-1),1L,land.price[i,'Year'])
  set(stock.landings,a:(a+l-1),2L,t(stocks[which(!is.na(stocks))]))
  set(stock.landings,a:(a+l-1),3L,species)
  set(stock.landings,a:(a+l-1),4L,state)
  set(stock.landings,a:(a+l-1),5L,region) 
  set(stock.landings,a:(a+l-1),6L,land)
  set(stock.landings,a:(a+l-1),7L,land.price[i,'Price'])
      
  a=a+l
}

stock.landings <- stock.landings %>% filter(stock != 'a')

save(stock.landings,file='stock.landings.rda') 


stock.landings.region <- tbl_df(stock.landings) %>%
  mutate(rel_price=price/(landings*1000)) %>%
  group_by(stock,region,year) %>% 
  summarise(total_landings = sum(landings,na.rm=T),
            price = mean(rel_price,na.rm=T),
            species = unique(species)) %>%
  mutate(cum.land = cumsum(total_landings),
         price = mean(price,na.rm=T)) %>%
  ungroup()

stock.landings.sum <- tbl_df(stock.landings) %>%
  mutate(rel_price=price/(landings*1000)) %>%
  group_by(stock,year) %>% 
  summarise(total_landings = sum(landings,na.rm=T),
            price = mean(rel_price,na.rm=T),
            species = unique(species),
            mainregion = names(tapply(landings,region,sum,na.rm=T))[which.max(tapply(landings,region,sum,na.rm=T))]) %>%
  mutate(cum.land = cumsum(total_landings),
         price = mean(price,na.rm=T)) %>%
  ungroup()

save(stock.landings.region,file='stock.landings.region.rda')

# join landings on management table
full.tab <- left_join(stock.landings.sum,
                      years.table,
                      by=c('stock' = 'Stock.name'))

full.tab.region <- left_join(stock.landings.region,
                      years.table,
                      by=c('stock' = 'Stock.name'))
@

I'm not sure what's going on here: need to check that out.

<<>>=
full.tab %>% 
  mutate(assessed = !is.na(Year.of.first.stock.assessment) & nchar(Year.of.first.stock.assessment)<5) %>%
  group_by(mainregion,year,assessed) %>%
  summarise(ns = n()) %>%
  ggplot() + geom_line(aes(col=mainregion,x=year,y=ns,linetype = assessed)) + ylab('Number of species landed') + xlab('Year') + 
  theme_bw()
@

For the survival analysis, we only need the last year and cumulative price and landings. I think.

<<results='hide'>>=
# only need year with assessment, or last year.
red.tab <- full.tab %>% 
  group_by(stock) %>%
  mutate(minyear = min(year,Year.of.fishery.development..stock.based.,na.rm = T),
         maxyear = max(year)) %>%
  filter((year == Year.of.first.stock.assessment) | (year == maxyear & (is.na(Year.of.first.stock.assessment) | nchar(Year.of.first.stock.assessment)>4)))


#final data table
year.table <- red.tab %>% 
  mutate(time = year - minyear)
@

To get taxonomy and habitat info for unassessed stocks (ie, those not in Mike's DB), taxise and rfishbase goes most of the way.

<<results='hide',cache=T,warning=FALSE,comment=>>=

# get habitat and taxonomy from fishbase and other DBs
require(rfishbase)
require(taxize)

year.table <- filter(year.table,!is.na(species))

fishbase <- load_taxa(update = T,limit = 35000)

fishspecs <- paste(fishbase$Genus,fishbase$Species)
fishmatch <- match(year.table$species, fishspecs)
fishes <- which(!is.na(fishmatch))

sp <- species(limit=35000)
habitats <- sp$DemersPelag
lengths <- sp$Length

fishhabitat <- habitats[fishmatch[!is.na(fishmatch) & is.na(year.table$habitat_MM)]]

year.table[!is.na(fishmatch) & is.na(year.table$habitat_MM), 'habitat_MM'] <- fishhabitat

fishtax <- fishbase[fishmatch[!is.na(fishmatch)], c('Family','Order','Class')]

year.table <- year.table %>% mutate(Order=NA,
                                    Family=NA,
                                    Class=NA)

year.table[fishes, c('Family','Order','Class')] <- fishtax

# Lengths
year.table$lengths <- sp$Length[match(year.table$species,sp$sciname)]


#### Inverts ###
# need to reload beyongd the cached part of sealifebase
sealifebase <- load_taxa(server='http://fishbase.ropensci.org/sealifebase',update = T,limit=120000)

invspecs <- paste(sealifebase$Genus,sealifebase$Species)
invmatch <- match(year.table$species, invspecs)
invs <- which(!is.na(invmatch))

inv_sp <- species(server='http://fishbase.ropensci.org/sealifebase',limit=120000)

inv_habitat <- inv_sp[invmatch[!is.na(invmatch) & is.na(year.table$habitat_MM)], 'DemersPelag']

year.table[!is.na(invmatch) & is.na(year.table$habitat_MM), 'habitat_MM'] <- inv_habitat

invtax <- sealifebase[invmatch[!is.na(invmatch)], c('Family','Order','Class')]

year.table[invs, c('Family','Order','Class')] <- invtax


### less resolution for habitat variable

year.table$habitat_MM[grepl('pelagic', year.table$habitat_MM)] <- 'pelagic'

year.table$habitat_MM[grepl('demersal', year.table$habitat_MM)] <- 'demersal'

year.table$habitat_MM[grepl('reef', year.table$habitat_MM)] <- 'reef'

# filter out higher taxonomy (i.e., rows that didn't match...)
year.table <- year.table %>% filter(!is.na(habitat_MM), !is.na(species),!is.na(Order)) %>% as.data.frame()


### length

invCodes <- sealifebase$SpecCode[match(year.table$species[is.na(year.table$lengths)],invspecs)]
invlength <- inv_sp$CommonLength[match(invCodes,inv_sp$SpecCode)]

year.table$lengths[is.na(year.table$lengths)] <- invlength


invCodes <- sealifebase$SpecCode[match(year.table$species[is.na(year.table$lengths)],invspecs)]
invlengths <- inv_sp$CommonLength[match(invCodes,inv_sp$SpecCode)]

year.table$lengths[is.na(year.table$lengths)] <- invlengths

year.table <- year.table %>% filter(!is.na(lengths))

@



\section{Simple Bayesian Weibull survival model}

Try a Bayesian truncated Weibull model to keep is simple to start with:

<<Jags setup>>=

# subset to data with price and landings data
year.table <- year.table %>% filter(!is.nan(price),year.table$time!=0)

#assessment time
devtime <- apply(cbind(year.table$Year.of.fishery.development..stock.based.,year.table$minyear),1,min,na.rm=T)

a.time <- as.numeric(year.table$Year.of.first.stock.assessment) - devtime

# true false censoring
censored <- is.na(a.time)

table(censored)

# censor time - improve here from the arbitrary 2010 cutoff for censored (non-assessed stocks)
ctime <- a.time+1
ctime[is.na(a.time)] <- year.table$time[is.na(a.time)]

# initial values for censored observations
time.inits <- ctime + 1
time.inits[!is.na(a.time)] <- NA

# habitat and family random effect - note - taxon is half way between habitat and family variables, try that too sometime

afs <- function(x) as.numeric(as.factor(x))

hab <- with(year.table,afs(habitat_MM))
n.hab <- length(unique(hab))

reg <- with(year.table,afs(mainregion))
n.region <- length(unique(reg))

order <- with(year.table,afs(Order))
n.order <- length(unique(order))
orderfam <- tapply(order,family,unique)

class <- with(year.table,afs(Class))
n.class <- length(unique(class))
classfam <- tapply(class,family,unique)
classord <- tapply(class,order,unique)

family <- with(year.table,afs(Family))
n.family <- length(unique(family))

# random effect for regions
# 

std <- function(x) (x-mean(x))/(2*sd(x))
year.table <- year.table %>% mutate(std_log10_length = std(log10(lengths)),
                                    std_log10_price = std(log10(price)),
                                    std_log10_land = std(log10(cum.land)))


# Covariate dataframe
COVS <- year.table %>%
  select(std_log10_length,
         std_log10_price,
         std_log10_land)

# replace TL for CA spiny lobster with something approximate for now since I can't find a good value
#covs$TL[is.na(covs$TL)] <- 3.2

n.covs <- ncol(COVS)
n.stocks <- nrow(COVS)
@

<<Run Jags model,eval=T,cache=T>>=
# set up jags model

require(rjags)

jags.data <- list(
  tmin=1,
  tmax=50,
  censored=as.numeric(censored),
  COVS=COVS,
  n.covs=n.covs,
  n.region=n.region,
  reg=reg,
  n.stocks=n.stocks,
  hab=hab,
  class=class,
  n.class=n.class,
  order=order,
  n.order=n.order,
  family=family,
  n.family=n.family,
  classfam=classfam,
  classord=classord,
  orderfam=orderfam,
  n.hab=n.hab,
  ctime=ctime,
  a.time=a.time
  )

# run model - short run for now...
JM <- jags.model('Weib_surv.R',data=jags.data,inits = list(a.time = time.inits),n.chains=3)

update(JM,n.iter=2000)

a.out <- coda.samples(JM,variable.names=c('tau',
                                          'betas',
                                          'habitat',
                                          'region',
                                          'orderfx',
                                          'classfx',
                                          'fp.sd.family',
                                          'fp.sd.order',
                                          'fp.sd.class',
                                          'fp.sd.habitat',
                                          'fp.sd.region',
                                          'region.pred',
                                          'hab.pred',
                                          'order.pred',
                                          'class.pred',
                                          'CS'),n.iter = 50e3, thin = 50)

save(a.out,year.table,COVS,full.tab,file=paste0('model.out',date(),'.rda'))
@

<<diagnostic plots, eval=T>>=

#plot(a.out)
#crosscorr.plot(a.out)

@


<<Get output>>=

# get coeffs from the chains - pull in some helper functions and Rdata from Bayesian model
source('helper_functs.R')
#load('~/Work/Dropbox/First year of assessment/FA_V001.RData')

# get posterior for cox-snell(CS) residuals from MCMC
mcmc.out <- do.call('rbind',a.out)
CS.full <- mcmc.out[,grepl('CS',colnames(mcmc.out))]

# just look at mean CS for now, can put posterior around it later

library(survival)


# Kaplan-Meyer non-parametric survival at CS - should follow exp(1) distribution
CS_func <- function(CS,censored){
  km.cs <- survfit(Surv(CS,!censored) ~ 1)
  summary.km.cs <- summary(km.cs)
  rcu <- summary.km.cs$time # Cox-Snell residuals of
  # uncensored points.
  surv.cs <- summary.km.cs$surv
  return(list(rcu,surv.cs))
}

CS.means <- apply(CS.full,1,CS_func,censored = censored)
CS.means <- do.call('rbind',lapply(CS.means, function(x) do.call('cbind',x)))

#CS = CS.means$post.mean
#CS_high = CS.means$q3
#CS_low = CS.means$q1

bins <- cut(CS.means[,1],breaks = quantile(CS.means[,1], probs = seq(0, 1, 0.005)),labels = FALSE)

CS.means <- data.frame(CS.means)
CS.means$bin <- bins
colnames(CS.means) <- c('time','CS','bin')

CS.mean.sum <- CS.means %>% group_by(bin) %>% 
  summarise(m_CS = mean(-log(CS)),
            m_t = mean(time),
            q1_CS = quantile(-log(CS),0.025),
            q3_CS = quantile(-log(CS),0.975))

ggplot(CS.mean.sum,aes(y=m_CS,x=m_t))+
  geom_point()+
 geom_ribbon(aes(ymin=q1_CS,ymax=q3_CS),col='grey80',alpha=0.3)+  
  geom_abline(aes(intercept=0,slope=1))+
  scale_x_continuous("Cox-Snell residual",expand=c(0,0))+
  ylab("Cumulative hazard")+
  theme_bw()

@

It looks as though the fit of the Weibull isn't too bad, some deviation is expected in the tails of the distribution, but over the bulk it seems to follow the 1:1 line fairly closely.

