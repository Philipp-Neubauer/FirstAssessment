\documentclass{article}

\begin{document}

\title{Analysis notes}
\maketitle

V0.0.2 PN

\section{Data manupulation}

<< Data input,results='hide',warning=FALSE>>=

# set dropbox folder for data

DB <- '~/Dropbox'

require(dplyr)
require(ggplot2)

years.table <- tbl_df(read.csv(file.path(DB,'First year of assessment/v7 Final dataset.csv'),
                              na.strings=c('','NA','#N/A'),
                              stringsAsFactors = F)
)

# crossref tables for non-assessed stocks
crossref <- tbl_df(read.csv(file.path(DB,
                                      'First year of assessment/crosref.csv'), 
                            na.strings=c('','NA','#N/A'), 
                            stringsAsFactors = F,dec = ",",header=T))

spec.ref <- read.csv(file.path(DB,
                               'First year of assessment/SpeciesCrossReference.csv'),
                     header=T,
                     stringsAsFactors = F)

reg.ref <- read.csv(file.path(DB,'First year of assessment/region_ref.csv'),header=F,stringsAsFactors = F)
@ 

For the landings data, I excluded a fair few species since they are irrelevant, and groupings since their definitons seem to be inconsistent, and landings therefore fluctuate suspiciously.

<<deal with landings>>=

land.price <- (read.csv(file.path(DB,'First year of assessment/landings-price.csv'), na.strings=c('','NA','#N/A'), stringsAsFactors = F,dec = ",")) %>%
  filter(!grepl('Turtle',Species,ignore.case = T),
         !grepl('Alligator',Species,ignore.case = T),
         !grepl('Coral',Species,ignore.case = T),
         !grepl('Sponge',Species,ignore.case = T),
         !grepl('UNC',Species,ignore.case = T),
         !grepl('WHALES',Species,ignore.case = T),
         !grepl('FROGS',Species,ignore.case = T),
         !grepl('finfishes',Species,ignore.case = T),
         !grepl('groundfishes',Species,ignore.case = T),
         State != "At-Sea Process, Pac.",
         State != 'Hawaii') 

land.price$Price <- as.numeric(gsub(',','',land.price[['Price']]))

land.price$Metric.Tons <- as.numeric(gsub(',','',land.price[['Metric.Tons']]))
@

Time series that start out as groups that were disaggregated (but without assessment), were re-aggregated at group level.

<<fix grouped landings data>>=

#fixes to grouped->disaggregated time series
land.price$Species[grepl('ABALONE',land.price$Species,ignore.case = T)] <- 'ABALONE'

land.price$Species[grepl('AMBERJACK',land.price$Species,ignore.case = T)] <- 'AMBERJACK'

land.price$Species[grepl('BARRAC',land.price$Species,ignore.case = T)] <- 'BARRACUDA'

# dissagregated from 2005
land.price$Species[grepl('SCUP',land.price$Species,ignore.case = T)] <- 'SCUPS OR PORGIES'

#remove shellfish and other generics
land.price <- land.price %>% filter(Species != 'SHELLFISH',
                                    Species != 'TUNAS',
                                    Species != 'SHARKS',
                                    Species != 'BILLFISHES')
@

Regions were matched based on states, where only large subdivision were kept (I.e., SE-sAtl and GoM does not figure)

<<>>=
matches <- match(land.price[,'State'],reg.ref[1,])
matches[is.na(matches)] <- 25
land.price$region <- as.vector(t(reg.ref[2,matches]))
land.price <- land.price %>% filter(region!='INLAND')
land.price$region <- factor(land.price$region)


land.price$Species[grepl('SHRIMP, MA',land.price$Species,ignore.case = T) & (land.price$Year <= 1961 | (land.price$Year >= 1972 & land.price$Year <= 1977)) & land.price$region == 'USEC-SE'] <- 'SHRIMP, WHITE'

@

I reduced the table down to only stocks that had at least 10t of catch at some point over the regional time-series.

<<Some subsetting,cache=TRUE>>=

# only keep stocks where 10t have been caught in a region at some point
suml <- tbl_df(land.price) %>% 
  group_by(region,Species,Year) %>%
  summarise(sums = sum(Metric.Tons,na.rm=T)) %>%
  mutate(flag = any(sums>10)) %>%
  filter(flag == T) %>%
  summarise(catch = sum(sums,na.rm=T)) %>%
  mutate(reg_spec = paste(region,Species))
  
lp <- apply(land.price[,c('Species','region')],1,function(x) {
  tf <- any(grepl(x[1],suml$reg_spec) & grepl(x[2],suml$reg_spec))
  return(tf)
  }) 

land.price <- land.price[lp,]

prop.cols <- grepl('prop',colnames(land.price))
stock.cols <- grepl('stock',colnames(land.price))
land.price[,prop.cols] <- apply(land.price[,prop.cols],2,as.numeric)

@

Stocks were defined as region-species/group, with landings and price totalled over the region.

<<results='hide',cache=TRUE>>=

require(data.table)

l = 84145
stock.landings <- data.table(year = rep(1,l),
                             stock = rep('a',l),
                             species = rep('a',l),
                             state = rep('a',l),
                             region = rep('a',l),
                             landings = rep(1,l),
                             price = rep(1,l))

# clunky, but easy:
a=1
for (i in 1:nrow(land.price)){
  #cat(i,'\n')
  
  stocks <- land.price[i,stock.cols]
  props <- land.price[i,prop.cols]
  region <- land.price[i,'region']
  state = land.price[i,'State']
  species <- spec.ref$SCIENTIFIC_NAME[match(land.price$Species[i],spec.ref$AFS_NAME)]
  
  if(any(!(is.na(stocks)))){
    land <- unlist(sapply(which(!is.na(stocks)),function(s) props[s]*land.price[i,'Metric.Tons']))
    
  } else { # apply a region-stock combo
    #region <- reg.ref[2,reg.ref[1,]==land.price[i,'State']]
    #region <- ifelse(!is.null(dim(region)), 'Inland', region)
    stocks  <-paste(region,land.price$Species[i])
    land <- land.price[i,'Metric.Tons']
  }
  
  
  l = length(which(!is.na(stocks)))
  
  set(stock.landings,a:(a+l-1),1L,land.price[i,'Year'])
  set(stock.landings,a:(a+l-1),2L,t(stocks[which(!is.na(stocks))]))
  set(stock.landings,a:(a+l-1),3L,species)
  set(stock.landings,a:(a+l-1),4L,state)
  set(stock.landings,a:(a+l-1),5L,region) 
  set(stock.landings,a:(a+l-1),6L,land)
  set(stock.landings,a:(a+l-1),7L,land.price[i,'Price'])
      
  a=a+l
}

stock.landings <- stock.landings %>% filter(stock != 'a')

save(stock.landings,file='stock.landings.rda') 


stock.landings.region <- tbl_df(stock.landings) %>%
  mutate(rel_price=price/(landings*1000)) %>%
  group_by(species,stock,year,region) %>% 
  summarise(total_landings = sum(landings,na.rm=T),
            price = mean(rel_price,na.rm=T)) %>%
  mutate(cum.land = cumsum(total_landings),
         price = mean(price,na.rm=T)) %>%
  ungroup()

save(stock.landings.region,file='stock.landings.region.rda')

# join landings on management table
full.tab <- left_join(stock.landings.region,
                      years.table,
                      by=c('stock' = 'Stock.name'))
@

I'm not sure what's going on here: need to check that out.

<<>>=
full.tab %>% 
  mutate(assessed = !is.na(Year.of.first.stock.assessment) & nchar(Year.of.first.stock.assessment)<5) %>%
  group_by(region,year,assessed) %>%
  summarise(ns = n()) %>%
  ggplot() + geom_line(aes(col=region,x=year,y=ns,linetype = assessed)) + ylab('Number of species') + xlab('Year') + 
  theme_bw()
@

For the survival analysis, we only need the last year and cumulative price and landings. I think.

<<results='hide'>>=
# only need year with assessment, or last year.
red.tab <- full.tab %>% 
  mutate(maxyear = max(year)) %>%
  filter((year == Year.of.first.stock.assessment) | (year == maxyear & (is.na(Year.of.first.stock.assessment) | nchar(Year.of.first.stock.assessment)>4)))

ref.time <- min(red.tab$year, na.rm=T)-1

#final data table
year.table <- red.tab %>% 
  mutate(time = year - ref.time)
@

To get taxonomy and habitat info for unassessed stocks (ie, those not in Mike's DB), taxise and rfishbase goes most of the way.

<<results='hide',cache=T,warning=FALSE,comment=>>=

# get habitat and taxonomy from fishbase and other DBs
require(rfishbase)

year.table <- filter(year.table,!is.na(species))

fishspecs <- paste(fishbase$Genus,fishbase$Species)
fishmatch <- match(year.table$species, fishspecs)
fishes <- which(!is.na(fishmatch))

sp <- ecology(fishspecs[fishmatch[fishes]],limit=100000)

sp <- species(limit=100000)
year.table$lengths <- sp$Length[match(year.table$species,sp$sciname)]


fishspecs

habitats <- species(fields='DemersPelag',limit=35000)$DemersPelag

fishhabitat <- habitats[fishmatch[!is.na(fishmatch) & is.na(year.table$habitat_MM)]]

year.table[!is.na(fishmatch) & is.na(year.table$habitat_MM), 'habitat_MM'] <- fishhabitat

fishtax <- fishbase[fishmatch[!is.na(fishmatch)], c('Family','Order','Class')]

year.table <- year.table %>% mutate(Order=NA,
                                    Family=NA,
                                    Class=NA)

year.table[fishes, c('Family','Order','Class')] <- fishtax


#### Inverts ###
# need to reload beyongd the cached part of sealifebase
sealifebase <- load_taxa(server=SEALIFEBASE_API,update = T,limit=120000)

sp_invs <- species(limit=120000, server=SEALIFEBASE_API)

inv_length <- sp_invs$Length[match(year.table$species,sp_invs$sciname)]
year.table$lengths[!is.na(inv_length)] <- inv_length[!is.na(inv_length)]

invspecs <- paste(sealifebase$Genus,sealifebase$Species)
invmatch <- match(year.table$species, invspecs)
invs <- which(!is.na(invmatch))

inv_habitats <- species(fields='DemersPelag', server='http://fishbase.ropensci.org/sealifebase',limit=120000)

inv_habitat <- inv_habitats[invmatch[!is.na(invmatch) & is.na(year.table$habitat_MM)], 'DemersPelag']

year.table[!is.na(invmatch) & is.na(year.table$habitat_MM), 'habitat_MM'] <- inv_habitat

invtax <- sealifebase[invmatch[!is.na(invmatch)], c('Family','Order','Class')]

year.table[invs, c('Family','Order','Class')] <- invtax

### less resolution for habitat variable

year.table$habitat_MM[grepl('pelagic', year.table$habitat_MM)] <- 'pelagic'

year.table$habitat_MM[grepl('demersal', year.table$habitat_MM)] <- 'demersal'

year.table$habitat_MM[grepl('reef', year.table$habitat_MM)] <- 'reef'

# filter out higher taxonomy (i.e., rows that didn't match...)
year.table <- year.table %>% filter(!is.na(habitat_MM), !is.na(species),region!='inland',!is.na(Order)) %>% as.data.frame()

@

Some preliminary plots:

<<>>=
year.table$Assessed <- ifelse(!is.na(as.numeric(year.table$Year.of.first.stock.assessment)),'Yes','No')

ggplot(year.table) + 
  geom_bar(aes(fill=Assessed,x=habitat_MM)) +
  coord_flip() + 
  theme_classic() + 
  xlab('Habitat') + 
  ylab('Count') + 
  theme(legend.position='bottom')

ggsave('Assessed_by_habitat.pdf',width = 6,height = 4)

ggplot(year.table) + 
  geom_bar(aes(fill=Assessed,x=Class)) + 
  coord_flip() + 
  theme_classic() + 
  ylab('Count') + 
  theme(legend.position='bottom')

ggsave('Assessed_by_class.pdf',width = 6,height = 4)

ggplot(year.table) + 
  geom_bar(aes(fill=Assessed,x=Order)) + 
  coord_flip() + 
  theme_classic() + 
  ylab('Count') + 
  theme(legend.position='bottom')

ggsave('Assessed_by_order.pdf',width = 6,height = 4)


@

\section{Simple Bayesian Weibull survival model}

Try a Bayesian truncated Weibull model to keep is simple to start with:

<<Jags setup>>=

# subset to data with price and landings data
year.table <- year.table %>% filter(!is.nan(price))
#assessment time
a.time <- as.numeric(year.table$Year.of.first.stock.assessment) - ref.time

# true false censoring
censored <- is.na(as.numeric(year.table$Year.of.first.stock.assessment))

table(censored)

# censor time - improve here from the arbitrary 2010 cutoff for censored (non-assessed stocks)
ctime <- a.time+1
ctime[is.na(a.time)] <- year.table$time[is.na(a.time)]

# initial values for censored observations
time.inits <- ctime + 1
time.inits[!is.na(a.time)] <- NA

# habitat and family random effect - note - taxon is half way between habitat and family variables, try that too sometime

afs <- function(x) as.numeric(as.factor(x))

hab <- with(year.table,afs(habitat_MM))
n.hab <- length(unique(hab))

order <- with(year.table,afs(Order))
n.order <- length(unique(order))

class <- with(year.table,afs(Class))
n.class <- length(unique(class))

family <- with(year.table,afs(Family))
n.family <- length(unique(family))

# random effect for regions
region <- data.frame(with(year.table,model.matrix(~region)))
n.reg <- length(unique(region))
# 

std <- function(x) (x-mean(x))/(2*sd(x))
year.table<- year.table %>% mutate(price = log10(price),
                      land = std(log(cum.land+1)))

year.table$price

# Covariate dataframe
covs <- year.table %>%
  select(land,
         price)

# replace TL for CA spiny lobster with something approximate for now since I can't find a good value
#covs$TL[is.na(covs$TL)] <- 3.2

COVS <- cbind(region, covs)
n.covs <- ncol(COVS)
n.stocks <- nrow(COVS)
@

<<Run Jags model,eval=T,cache=T>>=
# set up jags model

require(rjags)

jags.data <- list(
  censored=as.numeric(censored),
  COVS=COVS,
  n.covs=n.covs,
  n.stocks=n.stocks,
  hab=hab,
  class=class,
  n.class=n.class,
  order=order,
  n.order=n.order,
  family=family,
  n.family=n.family,
  n.hab=n.hab,
  ctime=ctime,
  a.time=a.time
  )

# run model - short run for now...
JM <- jags.model('Weib_surv.R',data=jags.data,inits = list(a.time = time.inits),n.chains=3)

update(JM,n.iter=10000)

a.out <- coda.samples(JM,variable.names=c('betas','habitat','fp.sd.family','fp.sd.order','fp.sd.class','fp.sd.hab','CS'),n.iter = 20e3, thin = 10)

save(a.out,year.table,COVS,full.tab,file=paste0('model.out',date(),'.rda'))

@

<<diagnostic plots, eval=T>>=

#plot(a.out)
#crosscorr.plot(a.out)

@


<<Get output>>=

# get coeffs from the chains - pull in some helper functions and Rdata from Bayesian model
source('helper_functs.R')
#load('~/Work/Dropbox/First year of assessment/FA_V001.RData')

# get posterior for cox-snell(CS) residuals from MCMC
mcmc.out <- do.call('rbind',a.out)
CS.full <- mcmc.out[,grepl('CS',colnames(mcmc.out))]

# just look at mean CS for now, can put posterior around it later

library(survival)


# Kaplan-Meyer non-parametric survival at CS - should follow exp(1) distribution
CS_func <- function(CS,censored){
  km.cs <- survfit(Surv(CS,!censored) ~ 1)
  summary.km.cs <- summary(km.cs)
  rcu <- summary.km.cs$time # Cox-Snell residuals of
  # uncensored points.
  surv.cs <- summary.km.cs$surv
  return(list(rcu,surv.cs))
}

CS.means <- apply(CS.full,1,CS_func,censored = censored)
CS.means <- do.call('rbind',lapply(CS.means, function(x) do.call('cbind',x)))

#CS = CS.means$post.mean
#CS_high = CS.means$q3
#CS_low = CS.means$q1

cuts <- quantile(CS.means[,1], probs = seq(0, 1, 0.01))
bins <- cut(CS.means[,1],breaks = cuts,labels = FALSE)
midpts <- (cuts[1:100]+lead(cuts)[1:100])/2

CS.means <- data.frame(CS.means)
CS.means$bin <- midpts[bins]
colnames(CS.means) <- c('time','CS','bin')

CS.mean.sum <- CS.means %>% group_by(bin) %>% 
  filter(!is.na(bin)) %>%
  summarise(m_CS = log(median(-log(CS),na.rm=T)),
            m_t = log(unique(bin)),
            q1_CS = log(quantile(-log(CS),0.025)),
            q3_CS = log(quantile(-log(CS),0.975)))

ggplot(CS.mean.sum,aes(y=m_CS,x=m_t))+
  geom_point()+
  geom_ribbon(aes(ymin=q1_CS,ymax=q3_CS),col='grey80',alpha=0.3)+  
  geom_abline(aes(intercept=0,slope=1))+
  scale_x_continuous("Cox-Snell residual",expand=c(0,0))+
  ylab("Cumulative hazard")+
  theme_bw()

ggsave('Model_fit.pdf')

@

It looks as though the fit of the Weibull isn't too bad, some deviation is expected in the tails of the distribution, but over the bulk it seems to follow the 1:1 line fairly closely.

