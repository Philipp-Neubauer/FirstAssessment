\documentclass{article}
\usepackage{subfig}
\usepackage{placeins}
\usepackage{pdflscape}
\begin{document}

\title{Are assessed stocks a representative sample of fished species in the US?}

\author{Philipp Neubauer, Dragonfly Data Science, Wellington, NZ \\
\and James T. Thorsen, NOAA Northwest Fisheries Science Center, Seattle 
\and            Michael C. Melnychuk, School of Aquatic and Fisheries Science, \\University of Washington, Seattle}

\maketitle


<<echo=FALSE>>=
require(knitr)
opts_chunk$set(warning=F, message = FALSE,echo=F,error=FALSE,cache=T, autodep=TRUE)
@

<<preamble,results='hide'>>=
#setwd("C:/Users/James.Thorson/Desktop/Project_git/FirstAssessment")
source('helper_functs.R')
require("dplyr")
require(xtable)
require("ggplot2")
library(survival)

#DB <- 'C:/Users/James.Thorson/Dropbox'
DB <- '~/Dropbox'
load(file.path(DB,"First year of assessment/Weibull_model_out.rda"),v=T)

# just for matching
year.table$Region <- year.table$mainregion
year.table$Habitat <- year.table$habitat_MM
year.table$region <- year.table$mainregion
year.table$habitat <- year.table$habitat_MM

coeffs <- tbl_df(get_coef_chains(model.out = a.out, 
                                 coef.names = 'betas',
                                 var.names = c('Length',
                                               'Cumulative landings',
                                               'Mean price per kg')))

# regressin coeffs are beta
coef_P <- coeffs %>%
  group_by(Parameter) %>%
  summarise(post.mean = mean(exp(MCMC)),
            post.P = mean(exp(MCMC) > 1))
@

\FloatBarrier
\newpage
\section{Introduction}

It is often said "what gets measured gets managed".  For over XXXX years (historical citation), fisheries scientists have measured
human impacts on ocean populations (finfishes and marine invertebrates) with the goal of balancing both the long-term sustainability
of human impacts with maximizing harvest (or value) from fishing.  In particular, stock assessments generally involve
estimating two measures of human impact: (1) fishing rate, i.e., the instantaneous mortality or annual fraction of the population that is harvested relative to an estimated target level, and (2) the population abundance, i.e., spawning biomass or reproductive output relative to an estimated target level.  The value of these two metrics can be plotted on a 2-dimensional "stock status" plot, and fisheries agencies are increasingly committed to maintaining fished populations in the "healthy" quadrant (i.e., fishing rate below a target level, and population abundance above a target level; citation).

Recently, the National Marine Fisheries Service (NMFS, the agency in charge of science supporting fisheries management in the United States) has committed to "end overfishing" for all marine species within regional fisheries management plans (with exceptions granted in a few circumstances; citation). In the US, overfishing is defined as any stock having annual harvest above limit levels. A target (or limit) harvest can in theory be calculated by combining a target harvest rate with a target population abundance.  However, the vast majority of overfishing limits are currently estimated using methods that do not individually calculate either harvest rate or population abundance (Berkson and Thorson 2015, Newman Berkson Sautoni 2015).  For example, depletion-corrected average catch (DCAC; MacCall 2009) is used to calculate an annual fishing limit for many stocks, but is not used to calculate population abundance. DCAC (and similar methods) can therefore be used to help "end overfishing" but is not otherwise informative about characteristics of the fished population. 

However, conservationists and ecologists will often be more interested in estimating population abundance (or abundance relative to equilibrium conditions) than estimating an overfishing limit (citations).  Estimating abundance generally requires applying a population model to available harvest data and an index of population depletion (either an index proportional to population abundance, or average size/age data);  in these cases, the population model essentially treats the historical fishing as a "depletion experiment" to estimate the fraction of the population that is fished every year.  In the following, we call these population models "stock assessments", although we acknowledge that other authors have used the term "stock assessment" more broadly to also include methods for estimating overfishing limits (e.g., DCAC). Although NMFS has estimated overfishing limits for the vast majority of fishes in US fisheries management plans, a much smaller percentage of fished species have a stock assessment (in our sense). This relative dearth of stock assessment models presumably arises because developing a stock assessment is time-consuming and requires extensive financial resources from NMFS and other interested parties (Geremont ref).

We  argue that stock assessments (population models for estimating absolute abundance for fished species) are important for many applied and theoretical questions regarding marine ecosystems.  However, there is little previous research regarding which fished species are more or less likely to receive sufficient attention to develop a stock assessment.  Understanding which species are more or less likely to be assessed could be useful for the following three reasons (among others):

1.  Unassessed stocks may receive less attention from the public or fisheries managers regarding management actions. Therefore, if a given taxon is less likely to be assessed, it might also be less likely to receive rapid or public attention when management changes are warrented.

2.  Output from stock assessments has often been used in meta-analysis models to understand ecological characteristics of marine fishes in general (Myers ref, Thorson et al. Fish and Fisheries 2015, other ideas...).  Therefore, any systematic bias in which stocks are assessed could also bias our ecological understanding of marine fishes.

3.  Stock assessments often require updates periodically (e.g., Pacific hake has been re-assessed annually from X through 2016), and agency resources might be fully expended while assessing a small fraction of stocks.  However, it is currently unknown whether the rate of assessing new species for the first time is increasing or decreasing.  If this rate is decreasing, this could indicate the need for additional public resources for stock assessment.  

We therefore seek to provide the first-ever quantitative analysis of which marine species are likely to have undergone a stock assessment.  To do so, we combine two databases representing all fished marine species in the United States:  a database of all landed species from 195X to 201X, and a database of management and stock assessment attributes for all US fishes with peer-reviewed stock assessments.  For each landed stock in each of four US regions (northeast, southeast, northwest, and southwest), we record the year that it first had a stock assessment; we treat any stock that does not have an assessment by 2015 as a "censored" observation (i.e., it might eventually have a peer-reviewed assessment)  We then apply a censored time-to-event model to answer the following questions:  (1) what economic or biological characteristics are associated with a high or low annual probability of being assessed for the first time? (2) which US region has assessed stocks relatively quickly or slowly? (3) are there certain taxa (e.g., invertebrates or sharks) that are substantially faster or slower-assessed given these biological and economic attributes? and (4) is the rate of stock assessment accelerating or deccelerating over time.  [Add one sentence high-line conclusion -- I know some people don't do this, but I think its a reasonable way to hook interest]

\FloatBarrier
\newpage
\section{Methods}

\subsection{Management database}

\subsection{Landings data}

\subsection{Data preparation}

\subsection{Model formulation}

\FloatBarrier
\newpage
\section{Results}
\begin{landscape}
<<assessed_landed,fig.cap='Timeline of a) the number of stocks landed by region and assessment status and b) proportion of landed stocks that are assessed. The vertical line marks the enactment of the Sustainable Fisheries Act of 1996',fig.subcap=c('Number of stocks', 'Proportion of stocks'),echo=FALSE,results='asis',fig.width=4,fig.height=4,out.width='0.7\\textwidth',fig.align='center'>>=

plot.tab <- full.tab %>% 
  mutate(assessed = !is.na(Year.of.first.stock.assessment) & year>Year.of.first.stock.assessment,
         Assessed = ifelse(assessed,'Yes','No')) %>%
  group_by(mainregion,year,Assessed) %>%
  summarise(ns = n()) 

plot.tab.prop <- full.tab %>% 
  mutate(assessed = !is.na(Year.of.first.stock.assessment) & year>Year.of.first.stock.assessment) %>%
  group_by(mainregion,year,assessed) %>%
  summarise(ns = n()) %>%
  mutate(total = ns/sum(ns)) %>%
  filter(assessed==T)

ggplot(plot.tab) + 
  geom_line(aes(col=mainregion,x=year,y=ns,linetype = Assessed)) + 
  ylab('Number of landed stocks') + 
  xlab('Year') +
  scale_linetype('Assessed')+
  scale_color_brewer('Region', type = 'qual', palette = 'Dark2')+
  geom_vline(aes(xintercept=1996))+
  theme_classic()

ggplot(plot.tab.prop) + 
  geom_line(aes(col=mainregion,x=year,y=total)) + 
  ylab('Proportion assessed') + 
  xlab('Year') + 
  scale_linetype('Assessed')+
  scale_color_brewer('Region', type = 'qual', palette = 'Dark2')+
  geom_vline(aes(xintercept=1996))+
  theme_classic()
@

\end{landscape}


<<>>=

year.table$Assessed <- ifelse(!is.na(as.numeric(year.table$Year.of.first.stock.assessment)),'Yes','No')

@

\begin{figure}[!h]
\centering
<<fig.width=5,fig.height=5,out.width='0.8\\textwidth'>>=
ggplot(year.table) + 
  geom_bar(aes(fill=Assessed,x=habitat_MM)) +
  coord_flip() + 
  theme_classic() + 
  xlab('Habitat') + 
  ylab('Count') + 
  theme(legend.position='bottom')
@
\caption{Assessment status at time of last known status (censoring time) by habitat}
\end{figure}

\begin{figure}[!h]
\centering
<<fig.width=5,fig.height=5,out.width='0.8\\textwidth'>>=
ggplot(year.table) + 
  geom_bar(aes(fill=Assessed,x=Order)) + 
  coord_flip() + 
  theme_classic() + 
  ylab('Count') + 
  theme(legend.position='bottom')
  @
\caption{Assessment status at time of last known status (censoring time) by phylum}
\end{figure}

\begin{figure}[!h]
\centering
<<fig.width=5,fig.height=5,out.width='0.8\\textwidth'>>=
ggplot(year.table) + 
  geom_bar(aes(fill=Assessed,x=Class)) + 
  coord_flip() + 
  theme_classic() + 
  ylab('Count') + 
  theme(legend.position='bottom')
@
\caption{Assessment status at time of last known status (censoring time) by Class}
\end{figure}


\begin{figure}
\centering
<<fig.width=4,fig.height=4,out.width='0.7\\textwidth'>>=

#assessment time
devtime <- apply(cbind(year.table$Year.of.fishery.development..stock.based.,year.table$minyear),1,min,na.rm=T)

a.time <- as.numeric(year.table$Year.of.first.stock.assessment) - devtime

# true false censoring
censored <- as.logical(is.na(a.time))

# Kaplan-Meyer non-parametric survival at t - should be linear with slope p
km.cs <- survfit(Surv(a.time,!censored) ~ 1)
summary.km.cs <- summary(km.cs)
rcu <- summary.km.cs$time 
surv.cs <- summary.km.cs$surv
plot(log(rcu),log(-log(surv.cs)),type="p",pch=16,xlab="log(t)",ylab="log(-log(S(t)))")
lm_fit <- lm(log(-log(surv.cs+1e-10))~log(rcu))$coefficients

abline(a=lm_fit[1],b=lm_fit[2],col=3,lwd=2); 
@
\caption{Appropriateness of the Weibull event-time model for the time-to-assessment dataset. If the Weibull applies, the time from fishery development to assessment should fall on a line with slope $p$ (the Weibull shape parameter) between $log(-log(\hat{S}(t)))$, where $\hat{S}(t)$ is the non-parametric Kaplan-Meyer estimate of survival at time $t$, and the log of $t$. Here, $p$ evaluates to \Sexpr{round(lm_fit[2],2)}, suggesting an increasing assessment rate with increasing time $t$.}
\end{figure}

\begin{figure}
\centering
<<fig.width=4,fig.height=4,out.width='0.7\\textwidth'>>=

# Kaplan-Meyer non-parametric survival at CS - should follow exp(1) distribution
CS.full <- tbl_df(get_coef_chains(model.out = a.out, coef.names = 'CS'))

# just look at mean CS for now, can put posterior around it later
CS.means <- CS.full %>%
  group_by(Parameter) %>%
  summarise(post.mean = mean(MCMC))

CS = CS.means$post.mean

devtime <- apply(cbind(year.table$Year.of.fishery.development..stock.based.,year.table$minyear),1,min,na.rm=T)

a.time <- as.numeric(year.table$Year.of.first.stock.assessment) - devtime
censored <- as.logical(is.na(a.time))

km.cs <- survfit(Surv(CS,!censored) ~ 1)
summary.km.cs <- summary(km.cs)
rcu <- summary.km.cs$time # Cox-Snell residuals of
                            # uncensored points.
surv.cs <- summary.km.cs$surv
plot(rcu,-log(surv.cs),type="p",pch=16,
xlab="Cox-Snell residual",ylab="Cumulative hazard")
abline(a=0,b=1,col=3,lwd=2); 

@
\caption{Model fit of the Weibull survival model, based on Cox-Snell residuals calculated at the posterior mean of the linear predictor. For a perfect fit all data points (solid points) would lie on the y=x line.}
\end{figure}

\FloatBarrier

\begin{table}
\centering
\small{
\caption{Posterior mean and $P(\beta>1)$ for model parameters. Parameters can be interpreted as multiplicative acceleration factors (i.e., $\beta$=2 suggests a stock is assessed twice as fast as a stock with $\beta=1$).}
\begin{tabular}{lrr}
\newline
Parameter & Posterior Mean & Bayesian P \\
\hline
<<table,results='asis',echo=FALSE>>=
print(xtable(data.frame(coef_P)),only.contents=TRUE, include.colnames=F, include.rownames=F,hline.after=NULL)
@
\end{tabular}
}
\end{table}

<<post_plot,fig.cap='Comparison of finite population standard deviation for random effects in the Weibull survival model. The circle shows the posterior median, with thick bars showing the inter-quartile range of the posterior and the thin line is the 95\\% confidence interval',fig.width=4,fig.height=4,out.width='0.7\\textwidth',fig.align='center'>>=

fp <- get_coef_chains(model.out = a.out, coef.names = 'fp' )

.simpleCap <- function(s) {
  
  paste(toupper(substring(s, 1, 1)), substring(s, 2),
        sep = "")
}

fp$Effect <- .simpleCap(do.call('rbind',strsplit(as.character(fp$Parameter),'\\.'))[,3])
fp$Effect[fp$Effect=='Hab'] <- 'Habitat'
fp$Effect <- factor(fp$Effect, levels = rev(unique(fp$Effect)))

fp %>% group_by(Effect) %>%
  summarise(means = median(MCMC),
            q1 = quantile(MCMC,0.025),
            q3 = quantile(MCMC,0.975),
            q11 = quantile(MCMC,0.25),
            q33 = quantile(MCMC,0.75)) %>%
  ggplot() + 
  geom_point(aes(x=Effect, y=means), size=4) +
  geom_linerange(aes(x=Effect,ymin=q1,ymax=q3),size=1) +
  geom_linerange(aes(x=Effect,ymin=q11,ymax=q33),size=2) +
  ylab('Finite populaition SD') +
  xlab('') + 
  theme_classic() +
  coord_flip()+
  theme(axis.text = element_text(colour='black'))

@

\begin{landscape}

<<surv_plot,fig.cap='Marginal probability of a stock being assessed as a function of time, for stocks of various taxonomic orders, class, regions and habitats. For taxonomic variables, only the eight levels with the most stocks represented in our dataset are shown. Marginal probabilities were evaluated at the mean of continuous covariates.',echo=FALSE,results='hide',fig.width=9,fig.height=5,out.width='1.4\\textwidth',fig.align='center'>>=

preds <- get_coef_chains(model.out = a.out, coef.names = 'pred' )

preds$Parameter <- as.character(preds$Parameter)

preds <- preds %>% 
  mutate(effect = do.call('rbind',strsplit(as.character(Parameter),'\\.'))[,1],
         Effect = .simpleCap(effect),
         idx = regmatches(Parameter,regexpr('*([0-9]*),([0-9])*',Parameter)),
         fx = as.numeric(do.call('rbind',strsplit(idx,','))[,1]),
         t = as.numeric(do.call('rbind',strsplit(idx,','))[,2]))

preds$Effect[preds$Effect=='Hab'] <- 'Habitat'
preds$effect[preds$effect=='hab'] <- 'habitat'

pred.plot <- preds %>% 
  group_by(Effect) %>%
  mutate(Group = levels(as.factor(year.table[,unique(Effect)]))[fx]) %>%
  ungroup() %>%
  group_by(Effect,Group,t) %>%
  summarise(p=median(MCMC),
            q1=quantile(MCMC,0.1),
            q3=quantile(MCMC,0.9))


p=0;gg<- list()
for(group in unique(pred.plot$Effect)){
  
  this <- names(sort(table(year.table[,group]),decreasing = T)[1:8])
  p=p+1;
  pp<- pred.plot %>% filter(Effect == group, Group %in% this)
  
  gg[[p]] <- ggplot(pp) + 
    geom_line(aes(x=t,y=p,col=Group,linetype=Group)) + 
    theme_classic() + 
    theme(axis.text = element_text(colour='black'))+
    ylab('Probability of being assessed') +
    xlab('Time (yr)') + 
    scale_colour_brewer(group,type='qual',palette='Dark2') + 
    scale_linetype_discrete(group)+
    coord_cartesian(expand = F)
}

gridExtra::grid.arrange(grobs=gg,ncol=2)

@
\end{landscape}

\begin{landscape}
<<Effect_plot,fig.cap='Summaries of estimated posterior distributions for a) continous covariates in the model, b) habitat random effects, and c) regional random effects. The circle shows the posterior median, with thick bars showing the inter-quartile range of the posterior and the thin line is the 95\\% confidence interval.',echo=FALSE,results='hide',fig.width=3,fig.height=3,out.width='0.5\\textwidth',fig.align='center',fig.subcap=c('Covariates', 'Habitat','Region')>>=

betas <- get_coef_chains(model.out = a.out, coef.names = 'betas\\[[0-9]*\\]', var.names = c('Length','Cumulative landings', 'Mean price per kg'))
betas$Effect <- 'Covariates'

habitats <- get_coef_chains(model.out = a.out, coef.names = 'habitat\\[[0-9]*\\]', var.names = levels(as.factor(year.table$habitat_MM)))
habitats$Effect <- 'Habitat'

regions <- get_coef_chains(model.out = a.out, coef.names = 'region\\[[0-9]*\\]', var.names = levels(as.factor(year.table$mainregion)))
regions$Effect <- 'Region'

fx.plot <- rbind(betas,habitats,regions)

p=0;gg<- list()
for(group in unique(fx.plot$Effect)){
  
  if(any(group %in% colnames(year.table))){
    this <- names(sort(table(year.table[,group]),decreasing = T)[1:8])
  } else {
    this <- unique(fx.plot$Parameter)
  }
  p=p+1;
  
  gg[[p]] <- fx.plot %>% filter(Effect == group, Parameter %in% this) %>%
    group_by(Parameter) %>%
  summarise(means = median(MCMC),
            q1 = quantile(MCMC,0.025),
            q3 = quantile(MCMC,0.975),
            q11 = quantile(MCMC,0.25),
            q33 = quantile(MCMC,0.75)) %>%
  ggplot() + 
  geom_point(aes(x=Parameter, y=means), size=4) +
  geom_linerange(aes(x=Parameter,ymin=q1,ymax=q3),size=1) +
  geom_linerange(aes(x=Parameter,ymin=q11,ymax=q33),size=2) +
  ylab('') +
  xlab('') +
  geom_hline(aes(yintercept=0), linetype=2) + 
  theme_classic() +
  coord_flip()+
  theme(axis.text = element_text(colour='black'))
}

gg

#gridExtra::grid.arrange(grobs=gg,nrow=1)
@

\end{landscape}

\end{document}