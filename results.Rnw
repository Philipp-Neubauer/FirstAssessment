\documentclass[american]{article}
\usepackage{geometry}
\usepackage[american]{babel}
\usepackage{setspace}
\usepackage{subfig}
\usepackage{placeins}
\usepackage{amsmath}
\usepackage{pdflscape}
\usepackage{longtable}
\usepackage[toc,page]{appendix}
\usepackage{array,booktabs}
\usepackage[style=authoryear,backend=biber]{biblatex}
\DeclareLanguageMapping{american}{american-apa}


\geometry{verbose,letterpaper,tmargin=2.54cm,bmargin=2.54cm,lmargin=2.54cm,rmargin=2.54cm}

\begin{document}

\title{Which fish stocks are assessed: an analysis and forecast of stock assessment in the United States}

\author{Philipp Neubauer, Dragonfly Data Science, Wellington, NZ \\
\and James T. Thorsen, NOAA Northwest Fisheries Science Center, Seattle 
\and            Michael C. Melnychuk, School of Aquatic and Fisheries Science, \\University of Washington, Seattle}

\maketitle

{\bf Target journals}

\begin{enumerate}
\item Fish \& Fisheries
\item ICES JMS
\item Journal of Applied Ecology (should be easy to write for this, but maybe have less of a fisheries audience)
\item Ecological Applications (ditto JAPPL)
\end{enumerate}

\begin{spacing}{1.9}

\begin{abstract}

At a minimum, fisheries management requires estimating harvested quantities or fishing rates so that the fishery can sustainably derive value from the resource base. Beyond this, many management agencies also define objectives regarding population status (e.g., biomass relative to biological targets). The different mandates of estimating harvest rates versus population status are often achieved using different types of models.  For example, agencies in the United States have a legislative mandate to "end overfishing" by setting harvest limits below biological targets, and have estimated these targets for many species using models that do not estimate population status. By contrast, estimating population status generally requires a "stock assessment", which we define as a statistical model of population dynamics to estimate population size relative to harvest.  Stock assessments are often more costly and resource-intensive than models that only estimate harvest limits, and to date only a subset of landed species have stock assessments. Here we quantitatively explore the factors influencing the probability that a previously unassessed stock in the United States will become the subject of a stock assessment. Using a statistical model based on time-to-event analysis and 600 coastal marine fish and invertebrate stocks, we quantify the impact of region, habitat, life-history, and economic factors on the annual probability of being assessed. Although the majority of landings come from assessed stocks in all regions, less than half of the regionally-landed species currently have a stock assessment. Landed tonnage is thus the dominant factor determining the rate of new assessments. However, we also find that a high ex-vessel price of landed fish leads to earlier stock assessment. The overall rate at which new stocks are assessed has been increasing since the 1950s, and a number of vulnerable groups such as rockfishes (Scorpaeniformes) and groundsharks (Carcharhiniformes) have a relatively high annual probability of being assessed after controlling for their relatively small tonnage and low price. Given the characteristics of species that are currently unassessed, our model suggests that the number of assessed stocks will increase slowly in future decades, as the landed tonnage and price for the remaining unassessed stocks makes it unlikely that current resources are sufficient to generate stock assessments for these species.

\end{abstract}

<<echo=FALSE>>=
require(knitr)
opts_chunk$set(warning=F, message = FALSE,echo=F,error=FALSE,cache=T, autodep=TRUE)
@

<<preamble,results='hide'>>=
DB <- '~/Dropbox'

# Settings for Jim's machine
if( Sys.info()["effective_user"] == "James.Thorson" ){
  setwd("C:/Users/James.Thorson/Desktop/Project_git/FirstAssessment")
  DB <- 'C:/Users/James.Thorson/Dropbox'
}

# Settings for Mike's machine
if( Sys.info()["effective_user"] == "MikeMelnychuk" ){
  setwd("E:/Documents/GitHub/FirstAssessment")
  DB <- 'E:/Dropbox/Projects'
}

source('helper_functs.R')
require("dplyr")
require(xtable)
require("ggplot2")
library(survival)

cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#0072B2", "#F0E442", "#D55E00", "#CC79A7","#999999")


load(file.path(DB,"First year of assessment/Weibull_model_output.rda"),v=T)
#load('model.outWed Dec  7 02:27:35 2016.rda',v=T)


# just for matching
year.table$Region <- year.table$mainregion
year.table$Habitat <- year.table$habitat_FB.SLB
year.table$region <- year.table$mainregion
year.table$habitat <- year.table$habitat_FB.SLB

beta_names <- c('Maximum length',
                'Mean ex-vessel price',
                'Maximum landings',
                'Interaction')

coeffs <- tbl_df(get_coef_chains(model.out = a.out, 
                                 coef.names = 'betas',
                                 var.names = beta_names))


tau <- tbl_df(get_coef_chains(model.out = a.out, 
                                 coef.names = 'tau',
                                 var.names = 'Rate'))
coeffs$Rate = tau$MCMC
# regressin coeffs are beta
coef_P <- coeffs %>%
  group_by(Parameter) %>%
  summarise(post.mean = mean(exp(MCMC)),
            acc = mean(exp(-MCMC/Rate)),
            post.P = mean(exp(MCMC) > 1))


# write current dataset
year.table %>% 
  select(stock, species, Year.of.first.stock.assessment, Region, Habitat) %>% 
  write.csv(file='dataset.csv',row.names = F,na = '')

years.table <- tbl_df(read.csv(file.path(DB,'First year of assessment/v9 Final dataset.csv'),
                              na.strings=c('','NA','#N/A'),
                              stringsAsFactors = F)
)

years.table %>% 
  filter(!Stock.name %in% year.table$stock) %>% 
  select(Stock.name,Year.of.first.stock.assessment)  %>% 
  write.csv(file='dataset_missed.csv',row.names = F)


@

\FloatBarrier
\newpage
\section{Introduction}

It is often said, "what gets measured, gets managed"  Fisheries scientists have measured human impacts on ocean populations of finfishes and marine invertebrates for over 100 years with the goal of balancing the value derived from fishing with the long-term sustainability of populations (\cite{smith_scaling_2007}).  In particular, stock assessments generally involve estimating two measures of human impact: (1) fishing rate, i.e., the instantaneous mortality or annual fraction of the population that is harvested relative to an estimated target level, and (2) the population abundance, i.e., spawning biomass or reproductive output relative to an estimated target level. Together these measures reflect the "stock status" of an assessed population, and fisheries agencies are increasingly committed to maintaining fished populations at fishing rates below target levels and population abundances above target levels (\cite{methot_implementing_2014}).

Recently, the National Marine Fisheries Service (NMFS, the agency in charge of science supporting fisheries management in the United States) has committed to "end overfishing" for all marine species within regional fisheries management plans (with exceptions granted in a few circumstances; citation). In the US, overfishing is defined as any stock having annual harvest rate or quantity above limit levels. A target (or limit) harvest can in theory be calculated by combining a target harvest rate with a target population abundance.  However, the vast majority of overfishing limits are currently estimated using methods that do not individually estimate either harvest rate or population abundance (\cite{berkson_determination_2015, newman2015current}).  For example, depletion-corrected average catch (\cite{maccall2009depletion}) is used to estimate an annual fishing limit for many stocks, but is not used to estimate population abundance. DCAC and similar methods can therefore be used to help "end overfishing", but are not otherwise informative about the status of a fished population. 

Conservationists and ecologists will often be more interested in estimating population abundance (or abundance relative to equilibrium conditions) than estimating an overfishing limit (e.g., \cite{hutchings_trends_2010}).  Estimating abundance generally requires applying a population model to available harvest data and an index of population depletion (either an index proportional to population abundance, or average size or age data); in these cases, the population model essentially treats the historical fishing as a "depletion experiment" to estimate the fraction of the population that is fished every year.  In the following, we consider these population models "stock assessments", although we acknowledge that other authors have used the term "stock assessment" more broadly to also include methods for estimating overfishing limits (e.g., DCAC \cite{maccall_depletion-corrected_2009}). Although NMFS has estimated overfishing limits for the vast majority of fishes in US fisheries management plans, a smaller percentage of fished species have a stock assessment as defined. The dearth of assessed species presumably arises because developing a stock assessment is time-consuming, typically has greater data input needs, and requires extensive financial resources from NMFS and other interested parties (\cite{dowling_low-_2013}).

Stock assessments (population models for estimating absolute abundance of fished species and associated biological reference points) are important for many applied and theoretical questions regarding marine ecosystems.  In particular, managing population stability (a characteristic of population size), rather than simply managing annual fishery removals, is possible only by estimating population abundance using stock assessment models.  However, there is little previous research regarding which fished species are more or less likely to receive sufficient attention to develop a stock assessment.  Understanding which species are more or less likely to be assessed could be useful for the following three reasons:

1.  Unassessed stocks may receive less attention from the public or fisheries managers when management changes are warranted.

2.  Output from stock assessments has often been used in meta-analyses to understand ecological characteristics of marine fishes in general (\cite{myers_maximum_1999, thorson2015giants}).  Therefore, any systematic bias in which stocks are assessed will also bias our ecological understanding of marine fishes.

3.  Stock assessments often require periodic updates (e.g., Pacific hake has been re-assessed annually from \Sexpr{year.table[grepl('Pacific hake',year.table$stock),'Year.of.first.stock.assessment']} through 2016; \cite[e.g., ][]{helser2006stock}), and agency resources might be fully expended while assessing a small fraction of possible stocks. If the rate of assessing new species  is decreasing, this could indicate the need for additional public resources for stock assessment.  

In this paper, we seek to provide a quantitative analysis of which marine species are likely to have undergone a stock assessment using a statistical population dynamics model.  To do so, we combine two databases representing fished coastal marine species in the continental United States and Alaska: a database of landed tonnage and value by species from 1950 to 2013, and a database of management and stock assessment attributes for US fishes and invertebrates with peer-reviewed stock assessments.  For each landed stock in each of four US regions (northeast, southeast, northwest, and southwest), we record the year that it first had a stock assessment, and we treat any stock that did not have an assessment by 2015 as a "censored" observation (i.e., it might eventually have a peer-reviewed assessment). We then apply a censored time-to-event model to answer the following questions:  (1) what economic and biological characteristics are associated with a high or low annual probability of being assessed for the first time?; (2) how has the rate of assessing stocks differed among US regions?; (3) are there certain taxa (e.g., invertebrates or sharks) that are assessed  substantially faster or slower-given these biological and economic attributes?; and (4) is the rate of stock assessment accelerating or decelerating over time? We show that ex-vessel price and landed tonnage are the main drivers of increasing rates of stock assessments, but some taxa defy these trends and are more likely to be assessed.

\section{Methods}

\subsection{Year of first stock assessment}

The year of first stock assessment for marine stocks previously assessed in the United States was determined primarily by interviews with regional stock assessment scientists, and supplemented by literature reviews of archived assessments. Many types of stock assessments are applied in the US, with varying levels of model complexity and input data requirements. Assessments for any given stock also tend to change over time, typically becoming more complex as warranted by available data. For consistency across populations, we defined a stock assessment as a single-species model of density-dependent population dynamics (e.g., including some combination of individual growth, recruitment, or aggregate surplus production) with the following criteria: (i) model parameters were estimated by fitting to abundance index and/or age or length compositional data; (ii) the model provided time series estimates of population abundance (e.g. total biomass, spawning biomass) and/or exploitation rates (e.g., fishing mortality or harvest fractions); and (iii) management benchmarks corresponding to these time series estimates were estimated within the assessment or were otherwise explicitly stated. Benchmarks included target reference points, reference points based on maximum sustainable yield (MSY) or its proxies, or initial population abundance; ratios of the time series and their corresponding reference points provide a relative index of stock status. Age-structured models, delay-difference models, biomass dynamics models, and surplus production models all qualified as assessment models.  We recognize that stock-reduction analyses (SRAs) are often used to estimate overfishing limits for stocks in the absence of a population-dynamics model fitted to data (\cite{maccall2009depletion, dick_depletion-based_2011}). However, stock-reduction analyses did not qualify as stock assessments under this definition because they typically are not fitted to abundance-index or compositional data.  

Assignments of first assessment year were compared with the NOAA Species Information System (SIS) database to ensure consistency. The SIS database does not contain information about when a stock was first assessed, so comparisons were restricted to recent years, assuming that stocks which qualified as assessed in a previous year continue to qualify as presently assessed. These comparisons generally showed consistency among datasets, with categories of ‘Levels of Stock Assessment Models’ in SIS aligning with our assignments. Of the nearly 200 stocks for which we assigned a year of first assessment, there were seven discrepancies with SIS classifications which resulted from violation of the abovementioned assumption. These stocks were previously assessed using populations models, but currently are assessed with less complex methods. For our analyses, we continue to consider these stocks as "assessed" and use our original assignments of when these stocks were first assessed.

\subsection{Defining un-assessed stocks}

Not all species landed in US fisheries are assessed using a stock assessment model, and some are only assessed in limited sub-regions. Our year-of-first assessment database therefore contained few records of unassessed stocks. Failing to include unassessed stocks would not allow us to make general inference about what types of stocks are assessed or not assessed, so we complement this year-of-first assessment database with data from NOAA's landings database. The NOAA landings database provides annual landings by species and state, whereas areas of stock distribution as defined in stock assessments comprise a wide array of spatial designations including state, regional, and national levels. To align databases, we identified the US states included within the area of distribution for all stocks in our dataset. Species with landings in states outside of these areas of assessed stocks were considered as ‘unassessed’ in those states. These assignments of ‘unassessed’ species:state combinations were pooled into species:region combinations so that an ‘unassessed’ stock represented a single species in a particular region that was not already represented by the area of distribution of an assessed stock. We distinguish four regions, defined as: Alaska (i.e., the Eastern Bering Sea, Gulf of Alaska, and Aleutian Islands); US West Coast (i.e., the federal waters of Oregon, Washington, and California); Northeast Coast (including the mid-Atlantic Coast); and Southeast Coast (including the South Atlantic Coast and Gulf of Mexico). These regions do not include the portion of US federally-managed waters in the Caribbean or central Pacific, because the year-of-first assessment database has not been expanded to these regions.

This definition of "unassessed stocks" is difficult to apply in the case of highly migratory species, which often span multiple regions or cross national jurisdiction. Further, the year of first assessment of highly migratory species that are assessed is likely influenced by other countries, unlike coastal stocks of the continental US and Alaska. We therefore excluded species that are typically assessed by Regional Fisheries Management Organisations, including tuna, billfish, and oceanic shark species. We also excluded salmon species from our analysis because our year-of-first assessment database has not been expanded to cover salmon species.

\subsection{Explanatory variables}

Several variables were considered as explanatory factors affecting the year in which a stock was first assessed. Region and habitat typically occupied by the population were each treated as a categorical random effect. Habitat types from FishBase \cite{froese2012fishbase} or SeaLifeBase \cite{palomares2010sealifebase} were compiled in R using rfishbase \cite{Boettiger_rfishbase_2012} and aggregated into six categories: deep sea (>200m; bathy-pelagic or bathy-demersal); benthic; demersal; benthopelagic; pelagic; and reef-associated. Adjustments were made to the default global species-level classifications for some populations to better reflect local habitat usage. Maximum body length of the species was also assigned to each population and used as a numerical predictor, drawing from FishBase and SeaLifeBase. The catch quantity and ex-vessel price of the population together determine landed value of the population; more valuable populations may be more likely to be assessed. We considered maximum annual landings prior to the first assessment and mean ex-vessel price (US.kg$^{-1}$) prior to thw first assessment as separate numerical predictors, drawn from the NOAA landings database. For unassessed stocks, the maximum annual landings throughout the time series and the ex-vessel price in the final year of the time series were used as values for these predictor variables.


\subsection{Time-to-event model}

To assess which factors drive the over-all rate of assessments and the time from first recorded landings to a full stock assessment in US stocks, we applied a time-to-event model. Also called termed survival models in the medical and ecological literature, these models account for censored data (i.e., species that are landed but not yet assessed) while modeling time-to-assessment within a parametric framework. We defined time to event as the time between first recorded landings and a full stock assessment. The first stock assessment (as defined by our criteria above) occured in 1960, and we therefore used 1960 as the first possible assessment eyar for stocks that were first landed prior to 1960. We thus assume, based on the first recorded assessment, that the technology (models, computers to fit models etc.) was not available prior to 1960 to conduct a full stock assessment.

The Weibull distribution is often used as a flexible model that has several desireable properties for this type of analysis, and one can easily check whether the Weibull model is appropriate for the data at hand (see Figure \ref{fig:Weibull_check}). The shape parameter of the Weibull density can be interpreted in terms of the rate of events occurring. A shape parameter $>$1 suggests an increasing rate of events, whereas a shape parameter $<$1 indicates an decreasing rate. This allows us to directly estimate the change in assessment rates over time. 

A further desirable property is that the model coefficient estimates can be interpreted both in terms of the ratio of event rates as well as time-to-event probabilities. For example, one can interpret a model coefficient as decreasing or increasing the likelihood of an event occurring at any particular time relative to the baseline (this is usually called the hazard ratio interpretation). Thus, the rate of events may be modified by a particular variable. A coefficient can also be interpreted by transformation into time-to-event parameters, which where time-to-event parameters represent a linear increase or decrease in the expected time until an event occurs. For example, in a hypothetical scenario, the median time-to-assessment of a demersal stock may be 0.5 times that of a pelagic stock, suggesting that it takes twice as long for pelagic stocks to get assessed. Such acceleration factors are just transformations of the parmeters obtained for the event rate interpretation - the two interpretations are easily exchangeable in the Weibull model.

We thus model time-to-assessment as Weibull- distributed with shape parameter $\tau$ and rate $\lambda$:

\begin{align}
T &\sim Weibull(\tau,\lambda) 
\end{align}   

The connection between the event rate and the time-to-event interpretations can be is made explicit by writing the Weibull density as a function of the product of the probability of the assessment occurring at time $t$ and the probability of the assessment not occurring prior to time $t$. 

\begin{align}
 f(t) &=  A(t)\times r(t)  \\
  &= \exp(-\lambda t^\tau) \times \lambda \tau t^{\tau-1}  
\end{align}

Thus, $P(T=t)$ depends on the probability of an assessment not having occurred prior to time $t$, $A(t) = 1-P(T\le t)=1-F(t)$, where $F(t) = \exp(-\lambda t^\tau)$ is the Weibull distribution function, and the rate $r(t)$ with which assessments occur at time $t$. 

We modeled the scale $\lambda$ of the Weibull distribution as a function of covariates and categorical variables:

\begin{align}
log(\lambda_{i,r,h,c,o,f}) = \beta X_i + \alpha_r + \gamma_h + \kappa_c + \omega_o + \zeta_f,
\end{align}

where $\beta$ is a row-vector of regression coefficients, and $X_i$ is a vector of continuous covariates. Continuous covariates were taken as the logarithms of mean ex-vessel price per kg, maximum landings, their interaction (i.e., mean ex-vessel price per kg $\times$ maximum landings) and species maximum length, standardised for the analysis. Categorical variables $\alpha$, $\gamma$, $\kappa$, $\omega$, and $\zeta_f$ were region, habitat, class, order, and family, respectively, all treated as  specific random effects. The model was estiamated within a Bayesian framework, using Markov Chain Monte Carlo (MCMC) as implemented in the JAGS package. MCMC was run using three chains of 210~000 iterations each, keeping every 100th iteration, with 10~000 iterations for each chain discarded as burn-in. This provided 6000 samples from the posterior distribution for each parameter.

All random effects were given half-Cauchy priors with a scale of $\Theta=100$, regression coefficients had vague normal priors with a precision of $1/\sigma^2 = 1e^{-5}$, and $\tau$ was estimated using a gamma distribution prior with parameters $a=b=1e^{-5}$. 

\section{Results}

<<prelim_results>>=

l.tab <- full.tab %>% 
  group_by(mainregion,stock) %>%
  filter(year==min(year)) %>% 
  group_by(mainregion,year) %>%
  summarise(n.landed = n()) %>% 
  mutate(c.landed = cumsum(n.landed))
  
a.tab <- full.tab %>% 
  group_by(mainregion,stock) %>%
  mutate(ya=as.numeric(as.numeric(Year.of.first.stock.assessment))) %>%
  group_by(mainregion,year) %>%
  summarise(n.assessed = sum(ya==year,na.rm=T),
            land.assessed = sum(total_landings[ya<=year],na.rm=T)/1000,
            land.unassessed = sum(total_landings[ya>year|is.na(ya)],na.rm=T)/1000) %>% 
  mutate(c.assessed = cumsum(n.assessed)) 
  
plot.tab <- inner_join(l.tab, a.tab) %>% 
  mutate(c.a = ifelse(is.na(c.assessed), 0, c.assessed),
    unassessed.landed = c.landed - c.a) %>%
  select(-c.a,-c.landed,-n.assessed,-n.landed,-land.assessed,-land.unassessed) %>%
  reshape2::melt(id.vars=c('mainregion','year')) %>%
  mutate(Assessed = ifelse(variable=='unassessed.landed','No','Yes'))

plot.tab.prop <- inner_join(l.tab, a.tab) %>% 
  mutate(p.assessed = c.assessed/c.landed) 
 
land_plot <- a.tab %>% 
  mutate(p.assessed = land.assessed/(land.assessed+land.unassessed))


@


The number of landed marine populations in the United States (excluding salmons and highly migratory species) increased steadily from the 1950s into the 1990s (Figure \ref{fig:assessed_landed}a). During this period, the number of landed populations in Alaska, West Coast, and Southeast regions approximately doubled, while the number of landed populations in the Northeast increased more slowly (but was already relatively high at the start of this period). Most of the newly-landed stocks were unassessed throughout this period; by the enactment of the Sustainable Fisheries Act in 1996, less than 30 populations in each of the four regions were assessed. As a proportion of all landed populations, however, the trend in assessed stocks has steadily increased in all regions since the 1970s or 1980s (Figure \ref{fig:assessed_landed}b). Currently the proportion of landed stocks that are assessed ranges from \Sexpr{round(plot.tab.prop$p.assessed[plot.tab.prop$mainregion=='USEC-SE' & plot.tab.prop$year == 2013]*100)}\% in the Southeast to \Sexpr{round(plot.tab.prop$p.assessed[plot.tab.prop$mainregion=='USWC-AK' & plot.tab.prop$year == 2012]*100)}\% in Alaska. In terms of regional landings, the assessment of large stocks in each region between the 1970s and 2000s lead to rapidly increasing proportions of total landed tonnage being comprised of assessed populations. By 1996, $>$\Sexpr{floor(min(land_plot$p.assessed[land_plot$mainregion!='USWC-48' & land_plot$year >= 2013]*100))}\% of landings in Alaska, Northeast, and Southeast regions were comprised of assessed stocks, and in the West Coast this proportion has increased rapidly from \Sexpr{round(land_plot$p.assessed[land_plot$mainregion=='USWC-48' & land_plot$year == 1996]*100)}\% in 1996 to $>$\Sexpr{floor(land_plot$p.assessed[land_plot$mainregion=='USWC-48' & land_plot$year == 2013]*100)}\% currently (Figure \ref{fig:assessed_landed}c). 

\begin{landscape}

\begin{figure}[!ht]
\centering
<<assessed_landed,echo=FALSE,results='asis',fig.width=9,fig.height=4,out.width='1.5\\textwidth'>>=


gga <- ggplot(plot.tab) + 
  geom_line(aes(col=mainregion,x=year,y=value,linetype = Assessed),size=1.3) + 
  ylab('Number of landed stocks') + 
  xlab('Year') +
  scale_linetype('Assessed')+
  guides(linetype=guide_legend(nrow=2))+
  scale_colour_manual('Region',values=cbPalette,guide='none') + 
  geom_vline(aes(xintercept=1996),linetype=3)+
  theme_classic()+
  theme(axis.text = element_text(color = 'black'),
        legend.position = 'top')

ggpr <- ggplot(plot.tab.prop) + 
  geom_line(aes(col=mainregion,x=year,y=p.assessed),size=1.3) + 
  ylab('Proportion of stocks assessed') + 
  xlab('Year') + 
  scale_linetype('Assessed')+
  scale_colour_manual('Region', values=cbPalette)+
  geom_vline(aes(xintercept=1996),linetype=3)+
  theme_classic()+ 
  guides(colour=guide_legend(nrow=2))+
  theme(axis.text = element_text(color = 'black'),
        legend.position = 'top')

ggl <- ggplot(land_plot) + 
  geom_line(aes(col=mainregion,x=year,y=p.assessed),size=1.3) + 
  ylab('Proportion of landings assessed') + 
  xlab('Year') + 
  scale_linetype('Assessed')+
  scale_colour_manual('Region', values=cbPalette)+
  guides(colour=guide_legend(title='',nrow=2, override.aes = list(col=NA)))+
  geom_vline(aes(xintercept=1996),linetype=3)+
  theme_classic()+
  theme(axis.text = element_text(color = 'black'),
        legend.position = 'top',
        legend.text = element_blank())

 require(cowplot)
  ggdraw() +
  draw_plot(gga, 0, 0, 1/3, 1) +
  draw_plot(ggpr, 1/3, 0, 1/3, 1) +
  draw_plot(ggl, 2/3, 0, 1/3, 1) +
  draw_plot_label(c("a", "b",'c'), c(1/12, 5/12,9/12), c(0.8, 0.8,0.8), size = 15)

@
\caption{Timeline of a) the number of stocks landed by region and assessment status, b) proportion of landed stocks that are assessed, and c) the proportion of landed tonnage derived from assessed stocks. The dotted vertical line marks the enactment of the Sustainable Fisheries Act of 1996.}
\label{fig:assessed_landed}
\end{figure}

\end{landscape}

The majority of landed populations were fish species (Figure \ref{fig:assessed}a), with Perciformes, Pleuronectiformes and Scorpaeniformes dominating both the number of assessed and unassessed stocks. Among invertebrate taxa, decapod species were the most commonly landed and also most commonly assessed. Demersal species represent a higher proportion of landed populations than species associated with other habitat types (Figure \ref{fig:assessed}b), and also accounted for the highest number and proportion of stock assessments.

\begin{figure}[!ht]
\centering
<<taxa,fig.width=7,fig.height=7,out.width='\\textwidth'>>=
year.table$Assessed <- ifelse(!is.na(as.numeric(year.table$Year.of.first.stock.assessment)),'Yes','No')
  
simpleCap <- function(s) {
  #s <- do.call('rbind',strsplit(x, " "))
  paste(toupper(substring(s, 1,1)), substring(s, 2),
      sep="")
}

yth <- year.table %>% mutate(hab = simpleCap(habitat_FB.SLB))

ggh <- ggplot(yth) + 
  geom_bar(aes(fill=Assessed,x=hab)) +
  coord_flip() + 
  theme_classic() + 
  scale_fill_grey( start = 0.4,guide='none') + 
  xlab('Habitat') + 
  ylab('Count') + 
  theme(axis.text.x = element_text(angle=90,hjust = 1,vjust=0.5),
        axis.text = element_text(color = 'black'))

yt <- year.table %>% 
  group_by(Order) %>% 
  mutate(class=substr(Class,1,2),
         ns = n()) %>% 
  filter(ns>=3)

inits <- substr(unique(yt$Class),1,2)

inits[inits=='Ma'] <- 'M'
yt$class[yt$class=='Ma'] <- 'M'
inits[inits=='Ec'] <- 'E'
yt$class[yt$class=='Ec'] <- 'E'

ggp <- ggplot(yt) + 
  geom_bar(aes(fill=Assessed,x=Order), width = 1) + 
  facet_grid(class~., drop = T,switch = "both", scales = "free_y", space = "free_y") +
  coord_flip() + 
  theme_cowplot() + 
  scale_fill_grey( start = 0.4) + 
  ylab('Count') + 
  theme(strip.background = element_rect(fill = 'grey80',colour = NA),
        legend.position = 'top')

  require(cowplot)
  ggdraw() +
  draw_plot(ggp, 0, 0, 1, 1) +
  draw_plot(ggh, 0.5, 0.15, 0.5, .5) +
  draw_plot_label(c("a", "b"), c(0, 0.55), c(1, 0.65), size = 15)

  @
\caption{Assessment status at time of last known status (censoring time) a) by taxonomic order and sorted by class and b) by habitat type. In a), classes are abbreviated as \Sexpr{paste(paste(inits,unique(yt$Class),sep=': '),collapse=', ')}, and only orders with more than three stocks are shown.}
\label{fig:assessed}
\end{figure}

We now turn to our time-to-event model to interpret which biological and fishery characteristics explain differences in annual probability of first assessment among stocks (see Appendix Figures \ref{fig:Weibull_check} and \ref{fig:CS} for model diagnostics).  Among the numerical covariates considered (Figure \ref{fig:fx_plot}, Table \ref{tab:fx}), maximum annual landings and ex-vessel price both had positive and strongly significant impacts on annual assessment probabilities. The effect of landings on assessment probability therefore explains how each region has a large proportion of landed tonnage derived from assessed populations (Fig. \ref{fig:assessed}c), but a smaller proportion of landed stocks being assessed (Fig. \ref{fig:assessed}b). The interaction between price and landings was negative, sugesting that price is influencial when landings are small, and vise-versa, the landed tonnage drives assessments for species that only fetch a low price. The effect size (per standard deviation) of maximum body length was smaller than that for price and landings, but was nevertheless different from zero, suggesting that larger species have been preferencially assessed.


\begin{figure}[!ht]
\centering
<<fx_plot,echo=FALSE,results='hide',fig.width=5,fig.height=8,out.width='0.6\\textwidth',fig.align='center'>>=

betas <- get_coef_chains(model.out = a.out, coef.names = 'betas\\[[0-9]*\\]', var.names = beta_names)
betas$Effect <- 'Num.'

print(levels(as.factor(year.table$habitat_FB.SLB)))

habitats <- get_coef_chains(model.out = a.out, coef.names = 'habitat\\[[0-9]*\\]', var.names = levels(as.factor(year.table$habitat_FB.SLB)))
habitats$Effect <- 'Habitat'
habitats$Parameter <- as.character(habitats$Parameter)
habitats$Parameter <- simpleCap(habitats$Parameter)

regions <- get_coef_chains(model.out = a.out, coef.names = 'region\\[[0-9]*\\]', var.names = levels(as.factor(year.table$mainregion)))
regions$Effect <- 'Region'

classes <- get_coef_chains(model.out = a.out, coef.names = 'classfx\\[[0-9]*\\]', var.names = levels(as.factor(year.table$Class)))
classes$Effect <- 'Class'


fx.plot <- rbind(betas,habitats,regions,classes) %>%
  group_by(Effect,Parameter) %>%
  summarise(means = (median(MCMC)),
            q1 = (quantile(MCMC,0.025)),
            q3 = (quantile(MCMC,0.975)),
            q11 = (quantile(MCMC,0.25)),
            q33 = (quantile(MCMC,0.75))) 

fx.plot$Effect <- factor(fx.plot$Effect,levels=unique(fx.plot$Effect)[c(3,2,4,1)])

ggplot(fx.plot) + 
  geom_point(aes(x=Parameter, y=means), size=4) +
  geom_linerange(aes(x=Parameter,ymin=q1,ymax=q3),size=1) +
  geom_linerange(aes(x=Parameter,ymin=q11,ymax=q33),size=2) +
  coord_flip() + 
  facet_grid(Effect~., drop = T,switch = "both", scales = "free_y", space = "free_y") +
  geom_hline(aes(yintercept=0), linetype=2) + 
  theme_cowplot() +
  ylab('Effect size')+
  theme(strip.background = element_rect())

#gridExtra::grid.arrange(grobs=gg,nrow=1)
@
\caption{Summaries of estimated posterior distributions for numeric (Num.) covariates in the model, regional random effects, habitat random effects, and taxonomic class random effects. Circles show posterior medians, thick bars show inter-quartile ranges of the posteriors, and thin lines show 95\% confidence intervals.}
\label{fig:fx_plot}
\end{figure}


Among explanatory random effects, taxonomy factors (order and class) explain a larger portion of residual variance than either habitat or region factors (Figure \ref{fig:post_plot}).  This is reflected in the probability of prior assessment in any given year after first being landed (Figures \ref{fig:fx_plot} and \ref{fig:surv_plot},, Table \ref{tab:fx}), for which octopii and squids (Cephalopods) and sharks (Elasmobranchs) have a slightly higher probability of prior assessment than bony-fishes (Actinopterygii) or other taxonomic classes.  Groundsharks (Carcharhiniformes),  rockfishes (Scorpaeniformes), and flatfishes (Pleuronectiformes) have the highest probability of prior assessment among taxonomic orders, each having a higher assessment probability relative to the average of their taxonomic classes (Figure \ref{fig:fx_plot_oder}, Table \ref{tab:fx}). Gadids (Gadidae) also have a relatively high assessment probability relative to the average for bony fishes. Habitat and regional effects were generally smaller than taxonomic effects. After controlling for other factors, benthic species had a higher probability of assessment than species from other habitats (in particular demersal species), and assessment probabilities were greatest for stocks in Alaska.   

\begin{figure}[!ht]
\centering
<<fx_plot_oder,echo=FALSE,results='hide',fig.width=5,fig.height=7,out.width='0.7\\textwidth'>>=

afs <- function(x) as.numeric(as.factor(x))
orders <- with(year.table,afs(Order))
class <- with(year.table,afs(Class))
classord <- tapply(class,orders,unique)


cl <- classes %>% 
  group_by(Parameter) %>% 
  mutate(iter=1:n()) %>% 
  tidyr::spread(Parameter,MCMC)

orderr <- get_coef_chains(model.out = a.out, coef.names = 'orderfx\\[[0-9]*\\]', var.names = levels(as.factor(year.table$Order)))
orderr$Effect <- 'Order'
orderr$class <- levels(as.factor(year.table$Class))[classord[match(orderr$Parameter,levels(as.factor(year.table$Order)))]]

orderr[,c('Class','Iter')] <- reshape2::melt(cl[,-c(1,2)][,classord])

orderr$Class <- as.character(orderr$Class)

orderr$Class[orderr$Class=='Gastropoda'] <- 'Gas.'

orderr %>%
  group_by(Parameter,Class) %>%
  summarise(omeans = mean(MCMC+Iter),
            cmeans = mean(Iter),
            oq1 = quantile(MCMC+Iter,0.025),
            cq1 = quantile(Iter,0.025),
            oq3 = quantile(MCMC+Iter,0.975),
            cq3 = quantile(Iter,0.975),
            oq11 = quantile(MCMC+Iter,0.25),
            cq11 = quantile(Iter,0.25),
            oq33 = quantile(MCMC+Iter,0.75),
            cq33 = quantile(Iter,0.75)) %>%
  group_by(Class) %>%
  mutate(ns = n()) %>% 
  filter(ns>1) %>%
  ggplot() + 
  geom_hline(aes(yintercept=0), linetype=3) + 
  geom_crossbar(aes(x=Parameter, y=cmeans,ymin=cq1,ymax=cq3),fill='grey80',col='grey50',alpha=0.5,size=0.01,fatten=100) +
  facet_grid(Class~., drop = T,switch = "both", scales = "free_y", space = "free_y") +
  coord_flip()+
  #scale_fill_grey(guide='none') + 
  geom_point(aes(x=Parameter, y=omeans), size=1) +
  geom_linerange(aes(x=Parameter,ymin=oq1,ymax=oq3),size=1) +
  #geom_linerange(aes(x=Parameter,ymin=oq11,ymax=oq33),size=2) +
  xlab('Order') +
  ylab('Effect size') +
  theme_cowplot() +
  #coord_flip()+
  theme(#axis.text.x = element_text(angle=90,hjust = 1,vjust=0.5),
        #strip.text = element_text(angle=90,hjust = 1,vjust=0.5),
        #panel.spacing = unit(0, "lines"), 
        strip.background = element_rect(fill='grey80'))

@
\caption{Summaries of estimated posterior distributions for random effects of orders within classes (Gas.: Gastropoda). For classes containing multiple nested orders in the dataset, grey lines show posterior means and coloured boxes show 95\% confidence intervals of class effects. Order effects are shown as relative to the class effect within which they are nested, with points showing posterior means and black lines showing 95\% confidence intervals.}
\label{fig:fx_plot_oder}
\end{figure}

Finally, we use our model to forecast annual assessment probabilities for all unassessed stocks in each region, and use this to calculate the expected proportion of assessed stocks through 2050 (Figure \ref{fig:surv_plot_region}). These projections rely on the values of maximum landings and ex-vessel price for all un-assessed stocks, and were calcualted from the final year of available time series data used for model fitting (usually 2013). Alaska is predicted to have the highest proportion of assessed populations throughout the 25-year projection window.  Notably, all regions show a relatively slow increase in the predicted proportion of assessed populations compared to the rapid increases in the observed proportions of assessed populations over the last 35 years (Fig. \ref{fig:assessed}b).  This occurs because stocks with a high assessment probability have typically been assessed early, so that remaining stocks have low landings, prices, or other characteristics associated with low annual assessment probability.      
     
<<surv_plot_region,fig.cap='Projected proportion of stocks assessed by region and calendar year, based on assessment probabilities of stocks within each region over the projected year range.',echo=FALSE,results='hide',fig.width=8,fig.height=4,out.width='1\\textwidth',fig.align='center'>>=

devtime <- apply(cbind(year.table$Year.of.fishery.development..stock.based.,year.table$minyear),1,min,na.rm=T)

a.time <- as.numeric(year.table$Year.of.first.stock.assessment) - devtime

# true false censoring
censored <- as.logical(is.na(a.time))

preds <- get_coef_chains(model.out = a.out, coef.names = '(mu\\[[0-9]*)')

mus <- tbl_df(preds) %>% filter(!grepl('\\.',Parameter))

mus$Parameter <- as.character(mus$Parameter)
mus$ymin <- 2016-rep(year.table$minyear,each=6000)
mus$cc <- rep(censored,each=6000)
mus$Region <- rep(year.table$mainregion,each=6000)

mus.p <- mus %>% 
  split(.$Parameter) %>%
  purrr::map(function(l) {
    lmin <- unique(l$ymin)
    tp <- sapply(seq(lmin,lmin+34),function(t) 1-exp(-l$MCMC*t^tau$MCMC))
    data.frame(time=2016:2050,mm=apply(tp,2,median),mq1=apply(tp,2,quantile,0.025),mq2=apply(tp,2,quantile,0.975),censored=unique(l$cc),Region=unique(l$Region))
  })


mpreda <- reshape2::melt(mus.p,id.vars=c('time','censored','Region'))
names(mpreda) <- c('time','censored','Region','Quantile','MCMC','Parameter')


preda <- tbl_df(mpreda) %>%
  group_by(Region, time, Quantile) %>%
  summarise(pro_assessed = mean(!censored),
            pro_pred = pro_assessed+(1-pro_assessed)*mean(MCMC[censored==T])) %>%
  tidyr::spread(key = Quantile,value = pro_pred)
  
preda$Region <- as.character(preda$Region)

preda$Region <- factor(preda$Region, levels = unique(preda$Region)[c(3,2,4,1)])

ggplot(preda) + 
 geom_line(aes(x=time,y=mm)) + 
  geom_line(aes(x=time,y=mq1), linetype=2) +
  geom_line(aes(x=time,y=mq2), linetype=2) + 
  geom_ribbon(aes(x=time,y=mm,ymin=mq1,ymax=mq2),alpha=0.4,col=NA) + 
  theme_cowplot() + 
  facet_grid(~Region) + 
  theme(strip.background = element_rect(colour=NA),
        axis.text.x = element_text(angle = 45, hjust=1))+
  ylab('Proportion assessed') +
  xlab('Calendar year') + 
  #scale_colour_manual(values=cbPalette) + 
  #scale_fill_manual(values=cbPalette) + 
    coord_cartesian(expand = F, ylim=c(0,1))


@


\section{Discussion}

We introduced this study with a common phrase from business management which equally pertains to natural resource management, "what gets measured, gets managed". The United States National Marine Fisheries Service (NMFS) currently estimates annual catch limits (ACLs) for the vast majority of fishes in federal fisheries management plans, and has established accountability measures that are triggered whenever recorded annual harvest exceeds the ACLs (\cite{methot_implementing_2014}). Similarly, state-based management agencies also monitor catches for many species and implement management actions once catches or catch-per-unit effort levels reach pre-specified limits. Thus, NMFS and other agencies both measure and manage annual harvest for the majority of US fishes.  However, different methods are used for setting ACLs. Stock-reduction analyses (SRAs) and other catch-only models (COMs), used to estimate ACLs for the majority of stocks in most federal US management regions (\cite{berkson_determination_2015}), do not estimate population size relative to management targets (\cite{dick_depletion-based_2011, wiedenmann_evaluation_2013}).  We have excluded SRAs and COMs from our definition of "formal stock assessments", and conclude that NMFS and other agencies are measuring population abundance only for those species that have a recent stock assessment.  

In some cases, it is possible to rebuild or maintain fish and invertebrate stocks at levels of sustainable harvest without using a formal stock-assessment model, using only SRAs or COMs (\cite[e.g., ][]{wetzel_model_2011,wetzel_performance_2011}). Specifically, COMs can be used to develop a harvest plan with fishing at a proportion of the estimated ACL, which is expected to have a pre-specified probability of maintaining population abundance near management targets (\cite{wetzel_performance_2011}). However, we see two main benefits to measuring population abundance for marine fishes beyond simply estimating ACLs:

1.  COMs generally involve managing a fishery to target a constant annual harvest, which is chosen to perform adequately on average: some stocks may be overfished, others may be underfished, but the average stock has appropriate fishing rates.  In contrast, formal stock assessments are likely to perform adequately over time for each individual stock:  some decades may be overfished, others may be underfished, but on average over time each individual stock is fished sustainably.  Both approaches are expected to perform well on average, but stock assessments improve the expected performance for each stock individually. This advantage is important for both conservationists and fishers who do not wish to see any given individual stock overfished, irrespective of whether or not the average stock is overfished. Not only does overfishing pose a conservation challenge for depleted stocks, but may impose stricter fishing limits for other stocks as a result of bycatch limits for the depleted stocks (\cite{hilborn_defining_2012,Melnychuk_catch_2012}). 

2.  The ability of formal stock assessments to inform harvest plans based on updated data has been repeatedly shown to improve management outcomes (\cite[e.g., ][]{carruthers_evaluating_2014}).  For example, managing with a harvest control rule in which  fishing mortality targets are updated based on stock assessment estimates of population abundance can substantially decrease variability in abundance and fishery catches, even relative to cases where a COM estimates sustainable fishing mortality rates perfectly (\cite{thorson_probability_2015}).  Updating harvest plans based on new data can also prevent cases in which stock reduction analyses over-estimate a sustainable fishing rate, which would otherwise collapse the fishery (\cite{wetzel_performance_2011}).  We therefore see benefits both to ocean conservation and to fishing industries by continuing to transition from management based on COMs to management based on formal stock assessments.  

There are many differences in quality and complexity among formal stock assessments.  NMFS categorizes assessments using five "tiers", and high-tier assessments are distinguished by having more or higher-quality data assimilated using a model that allows for greater attention to biological mechanisms and realism.  We have ignored these subtler distinctions here, and have instead used a single cutoff criterion, which essentially falls between statistical population models and SRAs. In general, our classification of ‘not assessed’ aligned with the SIS categories of 0 or 1 (Table \ref{}). We recommend future research that expands our model to include annual probabilities of transitioning among multiple categories (e.g., among six categories including unassessed and all five NMFS assessment tiers). This future analysis would allow greater detail regarding historical changes over time in the average quality of stock assessments, and may show alternative patterns among regions dependent on the level of assessment complexity consisered.

Given our operational definition of stock assessment, maximum landings was a particularly strong predictor of the year in which stocks were first assessed, and ex-vessel price was also positively correlated with the rate of assessments. The product of landings and price is a rough measure of the gross economic value derived from fish and invertebrate stocks. Fisheries managers and scientists must choose among several candidate species in a given region and devote stock assessment time and resources towards only a subset of these. If this choice reflects in part the landed value of stocks, then these results support previous findings (\cite{sethi_global_2010}) suggesting that fishery development is also driven primarily by landed tonnage and ex-vessel prices of fished species.

Certain taxonomic classes, or orders within classes, stood out as being more likely to have undergone a formal stock assessment after controlling for landings, ex-vessel price, and other factors. Elasmobranchs, and in particular groundsharks (Carchariniformes), had relatively high rates of stock assessment. This likely results from greatly increasing conservation interest in recent decades for shark species both in the United States and worldwide (\cite{dulvy_extinction_2014}). This high assessment rate after accounting for maximum landings may also result in part from the high discard rates of small coastal shark species often caught as bycatch in shrimp trawl or other fisheries (\cite{cortes_stock_2002}). Due to bycatch, our database values for shark landings may be smaller than true harvest, thus resulting in a compensatory increase in the estimated assessment rate for this taxon. Among bony fishes, flatfishes (Pleuronectiformes) and scorpaenfishes such as rockfishes and greenlings (Scorpaeniformes) had high rates of assessment. Results for Scorpaeniformes seem reasonable to us, given the number of Pacific rockfishes included, which have been a topic of conservation concern in Alaska and the US West Coast (\cite{clark_effect_1993,conway_socioeconomic_2008,myers_maximum_1999}). While cephalopod abundance is commonly estimated using catch-per-unit effort indices or  survey abundance indices (\cite{doubleday_global_2016}) rather than formal stock assessments, in the US most landed cephalopods are assessed (all are squid species). This may result from defined units of assesment having coastwide distributions rather than assuming a more disaggregated stock structure in which only some of the stocks would be assessed.  

Results from our model could be used to evaluate and control for systematic differences between assessed and unassessed US stocks in other analyses.  These differences are important because meta-analysis of assessed stocks is widely used to understand management performance and biological characteristics of marine fishes in general (\cite{thorson2015giants}).  To account for systematic differences between assessed and unassessed stocks, authors could use our model within a "propensity score matching" or “propensity score weighting” framework (\cite{ROSENBAUM01041983, Melnychuk_catch_2012}). For example, pairwise comparisons (or matching) between assessed and un-assessed stocks should involve stocks with similar likelihoods of being assessed. Similarly, calculated propensity scores can be used as predictor variables in regressions involving variables of interest to control for the non-random assessment probabilities among analyzed stocks.  If analysts find systematic differences in management outcomes or biological characteristics between assessed and unassessed stocks (e.g., systematic differences in recruitment compensation), then the relationship between the propensity of assessment and the variable of interest can be used to improve predictions for unassessed stocks.

Fish and invertebrate stocks in the United States are reaching saturation with respect to the rate of first assessment. Even though most stocks in all regions are as yet unassessed (Figure \ref{fig:assessed_landed}b), the predicted rate of increase in assessed stocks over the next few decades is slower than the rate observed over the last few decades because the stocks most likely to be assessed have already been assessed. However, this pattern is likely not characteristic of most countries, in part because of political mandates in the United States for quantifying the status of all fished stocks (\cite{methot_implementing_2014}). Most countries currently have a lower proportion of assessed stocks, and are likely still within a period of rapid increase in the proportion of assessed stocks. It is not necessarily the case that formal stock assessments are required for effectively managing fish and invertebrate stocks, as harvest control rules or in-season adjustments to fishing effort can instead be based on fishery-independent survey indices or fishery-dependent catch-per-unit effort indices rather than on stock status estimates from assessments. However, a logical leap from "what gets measured, gets managed" to "what is better measured, is better managed" suggests the value of better estimating stock status through the use of formal stock assessments.


\section{Acknowledgements}
We thank Cody Szuwalski for productive discussions while planning out the data set and analysis.  


\printbibliography   
\end{spacing}
\FloatBarrier
\newpage

\appendix
\renewcommand\thefigure{\thesection.\arabic{figure}}   
\renewcommand\thetable{\thesection.\arabic{table}}   
\setcounter{figure}{0} 
\section{A: Model fit}
\begin{figure}[!ht]
\centering

<<fig.width=4,fig.height=4,out.width='0.7\\textwidth'>>=

#assessment time


# Kaplan-Meyer non-parametric survival at t - should be linear with slope p
km.cs <- survfit(Surv(a.time,!censored) ~ 1)
summary.km.cs <- summary(km.cs)
rcu <- summary.km.cs$time 
surv.cs <- summary.km.cs$surv
plot(log(rcu),log(-log(surv.cs)),type="p",pch=16,xlab="log(t)",ylab="log(-log(S(t)))")
lm_fit <- lm(log(-log(surv.cs+1e-10))~log(rcu))$coefficients

abline(a=lm_fit[1],b=lm_fit[2],col=3,lwd=2); 
@
\caption{Appropriateness of the Weibull event-time model for the time-to-assessment dataset. If the Weibull applies, the time from first landings (or from first quantitative stock assessments in 1960 if a stock was landed before 1960) to the year of first assessment should fall on a line with slope $\tau$ (the Weibull shape parameter) between $log(-log(\hat{S}(t)))$, where $\hat{S}(t)$ is the non-parametric Kaplan-Meyer estimate of survival at time $t$, and the log of $t$. Here, $\tau$ evaluates to \Sexpr{round(lm_fit[2],2)} (slope of the green line), suggesting an increasing assessment rate with increasing time $t$.}
\label{fig:Weibull_check}
\end{figure}

\begin{figure}[!ht]
\centering
<<fig.width=4,fig.height=4,out.width='0.7\\textwidth'>>=

# Kaplan-Meyer non-parametric survival at CS - should follow exp(1) distribution
CS.full <- tbl_df(get_coef_chains(model.out = a.out, coef.names = 'CS'))

# just look at mean CS for now, can put posterior around it later
CS.means <- CS.full %>%
  group_by(Parameter) %>%
  summarise(post.mean = mean(MCMC))

CS = CS.means$post.mean

devtime <- apply(cbind(year.table$Year.of.fishery.development..stock.based.,year.table$minyear),1,min,na.rm=T)

a.time <- as.numeric(year.table$Year.of.first.stock.assessment) - devtime
censored <- as.logical(is.na(a.time))

km.cs <- survfit(Surv(CS,!censored) ~ 1)
summary.km.cs <- summary(km.cs)
rcu <- summary.km.cs$time # Cox-Snell residuals of
                            # uncensored points.
surv.cs <- summary.km.cs$surv
plot(rcu,-log(surv.cs),type="p",pch=16,
xlab="Cox-Snell residual",ylab="Cumulative hazard")
abline(a=0,b=1,col=3,lwd=2) 

@
\caption{Model fit of the Weibull survival model, based on Cox-Snell residuals calculated at the posterior mean of the linear predictor. For a perfect fit all data points (solid points) would lie on the y=x (green) line.}
\label{fig:CS}
\end{figure}

<<post_plot,fig.cap='Comparison of finite population standard deviation (i.e., variance attributed to each variable) for random effects in the Weibull survival model. Circles show posterior medians, thick bars show inter-quartile ranges of the posteriors, and thin lines show 95\\% confidence intervals.',fig.width=4,fig.height=4,out.width='0.4\\textwidth',fig.align='center'>>=

fp <- get_coef_chains(model.out = a.out, coef.names = 'fp' )

.simpleCap <- function(s) {
  
  paste(toupper(substring(s, 1, 1)), substring(s, 2),
        sep = "")
}

fp$Effect <- .simpleCap(do.call('rbind',strsplit(as.character(fp$Parameter),'\\.'))[,3])
fp$Effect[fp$Effect=='Hab'] <- 'Habitat'
fp$Effect <- factor(fp$Effect, levels = rev(unique(fp$Effect)))

fp %>% group_by(Effect) %>%
  summarise(means = median(MCMC),
            q1 = quantile(MCMC,0.025),
            q3 = quantile(MCMC,0.975),
            q11 = quantile(MCMC,0.25),
            q33 = quantile(MCMC,0.75)) %>%
  ggplot() + 
  geom_point(aes(x=Effect, y=means), size=4) +
  geom_linerange(aes(x=Effect,ymin=q1,ymax=q3),size=1) +
  geom_linerange(aes(x=Effect,ymin=q11,ymax=q33),size=2) +
  ylab('Finite population SD') +
  xlab('') + 
  theme_cowplot() +
  coord_flip()

@

\begin{landscape}

<<surv_plot,fig.cap='Marginal probability of a stock in category $k$ being assessed as a function of time ($P(T_k \\le t) = F_k(t) = \\exp(-\\lambda_k t^\\tau)$), for stocks of various taxonomic orders, class, regions and habitats. For taxonomic variables, only the eight levels with the most stocks represented in our dataset are shown. Marginal probabilities were evaluated at the mean of (centered) continuous covariates.',echo=FALSE,results='hide',fig.width=9,fig.height=4,out.width='1.6\\textwidth',fig.align='center'>>=

preds <- get_coef_chains(model.out = a.out, coef.names = 'pmu' )

preds$Parameter <- as.character(preds$Parameter)

preda <- preds %>% 
  split(.$Parameter) %>%
  purrr::map(function(l) {
    tp <- sapply(seq(0,50),function(t) 1-exp(-l$MCMC*t^tau$MCMC))
    data.frame(time=0:50,mm=apply(tp,2,median))
  })


mpreda <- reshape2::melt(preda,id.vars='time') %>% dplyr::select(-variable)
names(mpreda) <- c('time','MCMC','Parameter')

preda <- tbl_df(mpreda) %>% 
  mutate(effect = do.call('rbind',strsplit(as.character(Parameter),'\\.'))[,1],
         Effect = .simpleCap(effect),
         idx = as.numeric(regmatches(Parameter,regexpr('([0-9]+)',Parameter))))


preda$Effect[preda$Effect=='Hab'] <- 'Habitat'

pred.plot <- data.frame(preda) %>%
  rowwise() %>%
  mutate(Group = levels(as.factor(year.table[,unique(Effect)]))[idx])
  
p=0;gg<- list()
for(group in unique(pred.plot$Effect)){
  
  this <- names(sort(table(year.table[,group]),decreasing = T)[1:8])
  p=p+1;
  pp<- pred.plot %>% filter(Effect == group, Group %in% this)
  
  gg[[p]] <- ggplot(pp) + 
    geom_line(aes(x=time,y=MCMC,col=Group,linetype=Group)) + 
    theme_classic() + 
    theme(axis.text = element_text(colour='black'))+
    ylab('Probability of being assessed') +
    xlab('Time (yr)') + 
    scale_colour_manual(group,values=cbPalette) + 
    scale_linetype_discrete(group)+
    coord_cartesian(expand = F)
}

gridExtra::grid.arrange(grobs=gg,ncol=2)

@
\end{landscape}

<<>>=

orderr <- get_coef_chains(model.out = a.out, coef.names = 'orderfx\\[[0-9]*\\]', var.names = levels(as.factor(year.table$Order)))
orderr$Effect <- 'Order'


fx.tab <- rbind(betas,habitats,regions,classes,orderr) 
fx.tab$Rate <- tau$MCMC

fx.tab.sum <- fx.tab %>%
  group_by(Effect, Parameter) %>%
  summarise(m = median(exp(MCMC)),
            acc = median(exp(-MCMC/Rate)),
            p = mean(MCMC>0))

ptab <- order(match(fx.tab.sum$Effect, c('Covariates','Region','Habitat','Class','Order')))


@

\FloatBarrier
\newpage
\begin{center}
\begin{longtable}{llrrr}
\caption[Paramter estimates]{Posterior means of model parameters under interpretations of ratio of rates ($\theta$) or time-to-assessment ($\nu$), and probability $P(\theta>1)$ that increasing parameter values or stocks in a given category have an increased likelihood of assessment compared to the baseline. Under the ratio of rates interpretation, the rate effect $\theta$ represents rates at which stocks with different characteristics are assessed relative to a baseline of 1. Under the time-to-assessment interpretation, the time effect ν is a multiplicative acceleration factor, i.e., $\nu=0.5$ suggests a stock with these characteristics is assessed twice as fast as the average stock.} 
\label{tab:fx} \\

Effect & Category & Rate effect ($\theta$) & Time effect ($\nu$) & $P(\theta>1)$ \\
\addlinespace
\endfirsthead

\multicolumn{5}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\addlinespace 
Effect & Category & Rate effect ($\theta$) & Time effect ($\nu$) & $P(\theta>1)$ \\
\addlinespace 
\endhead

\addlinespace 
\hline 
\addlinespace 
\multicolumn{5}{r}{Continued on next page} \\
\endfoot

\endlastfoot

<<results="asis">>=
print(xtable(fx.tab.sum[ptab,]),
      hline.after = -1,
      only.contents = T,
      include.rownames = F, 
      include.colnames = F)
@
\end{longtable}
\end{center}

\end{document}
